{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from torch.jit import TracerWarning\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\",\n",
    "    category=TracerWarning,\n",
    "#     module=\"trace_elbo\",  # FIXME: What is the correct regex for module?\n",
    "#     lineno=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0: Average and variation in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(10):\n",
    "    for _ in range(1):  # Dummy loop to match other experiments.\n",
    "        generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=30,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.,\n",
    "#                     rho=np.logspace(0, 1, num=20) / np.logspace(0, 1, num=20).sum(),\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=5.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "#                 m_hyper_r=15.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=True,\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "#                 s=30,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=0.05,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "#                 m_hyper_r=5.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lagA=10,\n",
    "                lagB=50,\n",
    "                opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust=True,\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "        print(seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results0 = pd.DataFrame(results, columns=['seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_community_comparison(data=dict(\n",
    "    fit=fit['pi'],\n",
    "    sim=sim['pi']\n",
    "), scalex=0.12, scaley=0.03)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_genotype_comparison(data=dict(\n",
    "    fit=sf.genotype.mask_missing_genotype(fit['gamma'], fit['delta']),\n",
    "    sim=sf.genotype.mask_missing_genotype(sim['gamma'], sim['delta']),\n",
    "), scalex=0.12, scaley=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    ax.hist(results0[stat])\n",
    "    ax.set_title(stat)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Average and variation in fitting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for seed_fit in range(5):\n",
    "        generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=30,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.,\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=5.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=True,\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=0.05,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lagA=10,\n",
    "                lagB=50,\n",
    "                opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                progress=True,\n",
    "            ),\n",
    "            postclust=True,\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed_fit,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((seed_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "        print(seed_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results1 = pd.DataFrame(results, columns=['seed_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results1.set_index(['seed_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_community_comparison(data=dict(\n",
    "    fit=fit['pi'],\n",
    "    sim=sim['pi']\n",
    "), scalex=0.12, scaley=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results1['generr'], results1['comperr'], c=results1['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update experiments below to be more like the one above, now that I'm using the DP prior on rho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Benefits of increasing sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for n_fit in [20, 50, 100, 150, 200, 500]:\n",
    "        generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=30,\n",
    "            n_sim=1000,\n",
    "            g_sim=500,\n",
    "            n_fit=n_fit,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.,\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=5.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=True,\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=0.05,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lagA=10,\n",
    "                lagB=50,\n",
    "                opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust=True,\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((n_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "        print(n_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results2 = pd.DataFrame(results, columns=['n_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results2.set_index(['n_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Benefits of increasing depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for mu_hyper_mean_sim in ([0.1, 0.5, 1.0, 2.0, 5.0, 10.]):\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=mu_hyper_mean_sim,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=True,\n",
    "                preclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                    additional_strains_factor=0.1,\n",
    "                    progress=False,\n",
    "                ),\n",
    "                fit_kwargs=dict(\n",
    "                    gamma_hyper=0.01,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=True\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(mu_hyper_mean_sim, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((mu_hyper_mean_sim, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(mu_hyper_mean_sim, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results3 = pd.DataFrame(results, columns=['mu_hyper_mean_sim', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results3.set_index(['mu_hyper_mean_sim', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Benefits of increasing genotype positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for g_fit in reversed([100, 250, 500, 1000, 2000]):\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=2000,\n",
    "                n_fit=100,\n",
    "                g_fit=g_fit,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=True,\n",
    "                preclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                    additional_strains_factor=0.1,\n",
    "                    progress=False,\n",
    "                ),\n",
    "                fit_kwargs=dict(\n",
    "                    gamma_hyper=0.01,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(g_fit, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((g_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(g_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results4 = pd.DataFrame(results, columns=['g_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results4.set_index(['g_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: Strain-number estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for s_fit in [5, 10, 15, 30, 50]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=False,\n",
    "#                 preclust_kwargs=dict(\n",
    "#                     thresh=0.1,\n",
    "#                     additional_strains_factor=0.1,\n",
    "#                     progress=False,\n",
    "#                 ),\n",
    "                fit_kwargs=dict(\n",
    "                    s=s_fit,\n",
    "                    gamma_hyper=0.01,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=True,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(g_fit, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((s_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(s_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results5 = pd.DataFrame(results, columns=['s_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results5.set_index(['s_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_community_comparison(data=dict(\n",
    "    fit=fit['pi'],\n",
    "    sim=sim['pi']\n",
    "), scalex=0.12, scaley=0.03)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_genotype_comparison(data=dict(\n",
    "    fit=sf.genotype.mask_missing_genotype(fit['gamma'], fit['delta']),\n",
    "#     sim=sf.genotype.mask_missing_genotype(sim['gamma'], sim['delta']),\n",
    "), scalex=0.12, scaley=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6: Effects of genotype fuzzyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for gamma_hyper_fit in [1e-8, 1e-5, 1e-2, 5e-2, 1e-1, 5e-1, 1e0]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=False,\n",
    "#                 preclust_kwargs=dict(\n",
    "#                     thresh=0.1,\n",
    "#                     additional_strains_factor=0.1,\n",
    "#                     progress=False,\n",
    "#                 ),\n",
    "                fit_kwargs=dict(\n",
    "                    s=30,\n",
    "                    gamma_hyper=gamma_hyper_fit,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(gamma_hyper_fit, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((gamma_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(gamma_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results6 = pd.DataFrame(results, columns=['gamma_hyper_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results6.set_index(['gamma_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7: Effects of diversity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for rho_hyper_fit in [5, 1, 0.5, 0.1, 0.05, 0.01, 1e-5]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=False,\n",
    "#                 preclust_kwargs=dict(\n",
    "#                     thresh=0.1,\n",
    "#                     additional_strains_factor=0.1,\n",
    "#                     progress=False,\n",
    "#                 ),\n",
    "                fit_kwargs=dict(\n",
    "                    s=35,\n",
    "                    gamma_hyper=0.05,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=rho_hyper_fit,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(rho_hyper_fit, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((rho_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(rho_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results7 = pd.DataFrame(results, columns=['rho_hyper_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results7.set_index(['rho_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 8: Effects of heterogeneity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for pi_hyper_fit in [1e-4, 1e-3, 1e-2, 5e-1, 1e0, 1e1, 1e2]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=True,\n",
    "                preclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                    additional_strains_factor=0.1,\n",
    "                    progress=False,\n",
    "                ),\n",
    "                fit_kwargs=dict(\n",
    "                    gamma_hyper=0.05,\n",
    "                    pi_hyper=pi_hyper_fit,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(pi_hyper_fit, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((pi_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(pi_hyper_fit, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results8 = pd.DataFrame(results, columns=['pi_hyper_fit', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results8.set_index(['pi_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 9: Effects of preclustering threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for preclust_thresh in [0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.2]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=True,\n",
    "                preclust_kwargs=dict(\n",
    "                    thresh=preclust_thresh,\n",
    "                    additional_strains_factor=0.1,\n",
    "                    progress=False,\n",
    "                ),\n",
    "                fit_kwargs=dict(\n",
    "                    gamma_hyper=0.05,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(preclust_thresh, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((preclust_thresh, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(preclust_thresh, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results9 = pd.DataFrame(results, columns=['preclust_thresh', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results9.set_index(['preclust_thresh', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 10: Effects of strain merging (postclustering) threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for postclust_thresh in [0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.2]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=5.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=False,\n",
    "#                 preclust_kwargs=dict(\n",
    "#                     thresh=0.1,\n",
    "#                     additional_strains_factor=0.1,\n",
    "#                     progress=False,\n",
    "#                 ),\n",
    "                fit_kwargs=dict(\n",
    "                    s=50,\n",
    "                    gamma_hyper=0.05,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": 1e-0}),\n",
    "                    progress=False,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=postclust_thresh,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(postclust_thresh, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((postclust_thresh, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(postclust_thresh, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results10 = pd.DataFrame(results, columns=['postclust_thresh', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results10.set_index(['postclust_thresh', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 11: Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(5):\n",
    "    for learning_rate in [0.05, 0.1, 0.5, 1., 1.5, 2.]:\n",
    "        try:\n",
    "            generr, comperr, mcomperr, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "                s_sim=30,\n",
    "                n_sim=100,\n",
    "                g_sim=500,\n",
    "                n_fit=100,\n",
    "                g_fit=500,\n",
    "                sim_kwargs=dict(\n",
    "                    data=dict(\n",
    "                        alpha_hyper_mean=100.,\n",
    "                    ),\n",
    "                    gamma_hyper=0.01,\n",
    "                    delta_hyper_temp=0.01,\n",
    "                    delta_hyper_p=0.7,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=5.,\n",
    "                    mu_hyper_mean=1.,\n",
    "                    mu_hyper_scale=0.5,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5/0.01,\n",
    "                    device='cpu'\n",
    "                ),\n",
    "                preclust=True,\n",
    "                preclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                    additional_strains_factor=0.1,\n",
    "                    progress=False,\n",
    "                ),\n",
    "                fit_kwargs=dict(\n",
    "                    gamma_hyper=0.05,\n",
    "                    pi_hyper=0.5,\n",
    "                    rho_hyper=0.05,\n",
    "                    mu_hyper_mean=5,\n",
    "                    mu_hyper_scale=5.,\n",
    "                    delta_hyper_temp=0.1,\n",
    "                    delta_hyper_p=0.9,\n",
    "                    alpha_hyper_hyper_mean=100.,\n",
    "                    alpha_hyper_hyper_scale=10.,\n",
    "                    alpha_hyper_scale=0.5,\n",
    "                    epsilon_hyper_alpha=1.5,\n",
    "                    epsilon_hyper_beta=1.5 / 0.01,\n",
    "                    device='cpu',\n",
    "                    lagA=10,\n",
    "                    lagB=50,\n",
    "                    opt=pyro.optim.Adamax({\"lr\": learning_rate}),\n",
    "                    progress=True,\n",
    "                ),\n",
    "                postclust=True,\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "                seed_sim=seed,\n",
    "                seed_fit=seed,\n",
    "                quiet=True,\n",
    "            )\n",
    "        except (ValueError, RuntimeError) as err:\n",
    "            sf.logging_util.info(learning_rate, seed, f\"Estimation failed with: {err}\")\n",
    "        else:\n",
    "            results.append((learning_rate, seed, generr, comperr, mcomperr, entropy, runtime))\n",
    "            print(learning_rate, seed, generr, comperr, mcomperr, entropy, runtime, sep='\\t')\n",
    "\n",
    "results11 = pd.DataFrame(results, columns=['learning_rate', 'seed', 'generr', 'comperr', 'mcomperr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'mcomperr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results11.set_index(['learning_rate', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Big matrix plot.\n",
    "\n",
    "all_results = [\n",
    "    (results1, 'seed_fit', 'linear', 1),\n",
    "    (results2, 'n_fit', 'log', 2),\n",
    "    (results3, 'mu_hyper_mean_sim', 'log', 3),\n",
    "    (results4, 'g_fit', 'log', 4),\n",
    "    (results5, 's_fit', 'log', 5),\n",
    "    (results6, 'gamma_hyper_fit', 'log', 6),\n",
    "    (results7, 'rho_hyper_fit', 'log', 7),\n",
    "    (results8, 'pi_hyper_fit', 'log', 8),\n",
    "    (results9, 'preclust_thresh', 'linear', 9),\n",
    "    (results10, 'postclust_thresh', 'linear', 10),\n",
    "]\n",
    "\n",
    "all_stats = [\n",
    "    ('generr', 'log'),\n",
    "    ('comperr', 'log'),\n",
    "    ('mcomperr', 'log'),\n",
    "    ('entropy', 'linear'),\n",
    "    ('runtime', 'log')\n",
    "]\n",
    "\n",
    "nres = len(all_results)\n",
    "nstat = len(all_stats)\n",
    "\n",
    "fig, axs = plt.subplots(nstat, nres, figsize=(3 * nres, 2 * nstat), sharex='col', sharey='row')\n",
    "\n",
    "for (stat, scale_y), row in zip(all_stats, axs):\n",
    "    for (results, indexer, scale_x, title), ax in zip(all_results, row):\n",
    "        results.set_index([indexer, 'seed'])[stat].unstack().plot(ax=ax)\n",
    "        ax.set_ylabel(stat)\n",
    "        ax.set_xlabel(indexer)\n",
    "        ax.legend_.set_visible(False)\n",
    "        ax.set_xscale(scale_x)\n",
    "        ax.set_yscale(scale_y)\n",
    "#        ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()\n",
    "#ax.legend(bbox_to_anchor=(1, 1), title='replicate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo: Good accuracy with realistic conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(20):\n",
    "    generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "        s_sim=20,\n",
    "        n_sim=200,\n",
    "        g_sim=1000,\n",
    "        n_fit=200,\n",
    "        g_fit=1000,\n",
    "        sim_kwargs=dict(\n",
    "            data=dict(\n",
    "                alpha_hyper_mean=100.\n",
    "            ),\n",
    "            gamma_hyper=0.01,\n",
    "            delta_hyper_temp=0.01,\n",
    "            delta_hyper_p=0.9,\n",
    "            pi_hyper=0.5,\n",
    "            rho_hyper=2.,\n",
    "            mu_hyper_mean=10.,\n",
    "            mu_hyper_scale=0.5,\n",
    "            m_hyper_r=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5/0.01,\n",
    "            device='cpu'\n",
    "        ),\n",
    "        preclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "            additional_strains_factor=0.1,\n",
    "            progress=False,\n",
    "        ),\n",
    "        fit_kwargs=dict(\n",
    "            gamma_hyper=0.01,\n",
    "            pi_hyper=1.0,\n",
    "            rho_hyper=0.5,\n",
    "            mu_hyper_mean=5,\n",
    "            mu_hyper_scale=5.,\n",
    "            m_hyper_r=10.,\n",
    "            delta_hyper_temp=0.1,\n",
    "            delta_hyper_p=0.9,\n",
    "            alpha_hyper_hyper_mean=100.,\n",
    "            alpha_hyper_hyper_scale=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5 / 0.01,\n",
    "            device='cuda',\n",
    "            lag=10,\n",
    "            lr=2e-0,\n",
    "            progress=True\n",
    "        ),\n",
    "        postclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "        ),\n",
    "        seed_sim=seed,\n",
    "        seed_fit=seed,\n",
    "        quiet=True,\n",
    "    )\n",
    "    results.append((seed, generr, comperr, scounter, entropy, runtime))\n",
    "    print(seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results_d0 = pd.DataFrame(results, columns=['seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    ax.hist(results_d0[stat], bins=5)\n",
    "    ax.set_title(stat)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}