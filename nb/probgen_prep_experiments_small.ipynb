{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from torch.jit import TracerWarning\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\",\n",
    "    category=TracerWarning,\n",
    "#     module=\"trace_elbo\",  # FIXME: What is the correct regex for module?\n",
    "#     lineno=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0: Average and variation in fitting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed_fit in range(10):\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=True,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=2e-0,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed_fit,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((seed_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(seed_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results0 = pd.DataFrame(results, columns=['seed_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results0.set_index(['seed_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Average and variation in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(10):\n",
    "    generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "        s_sim=20,\n",
    "        n_sim=100,\n",
    "        g_sim=500,\n",
    "        n_fit=100,\n",
    "        g_fit=500,\n",
    "        sim_kwargs=dict(\n",
    "            data=dict(\n",
    "                alpha_hyper_mean=100.\n",
    "            ),\n",
    "            gamma_hyper=0.01,\n",
    "            delta_hyper_temp=0.01,\n",
    "            delta_hyper_p=0.7,\n",
    "            pi_hyper=0.5,\n",
    "            rho_hyper=2.,\n",
    "            mu_hyper_mean=1.,\n",
    "            mu_hyper_scale=0.5,\n",
    "            m_hyper_r=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5/0.01,\n",
    "            device='cpu'\n",
    "        ),\n",
    "        preclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "            additional_strains_factor=0.1,\n",
    "            progress=False,\n",
    "        ),\n",
    "        fit_kwargs=dict(\n",
    "            gamma_hyper=0.01,\n",
    "            pi_hyper=1.0,\n",
    "            rho_hyper=0.5,\n",
    "            mu_hyper_mean=5,\n",
    "            mu_hyper_scale=5.,\n",
    "            m_hyper_r=10.,\n",
    "            delta_hyper_temp=0.1,\n",
    "            delta_hyper_p=0.9,\n",
    "            alpha_hyper_hyper_mean=100.,\n",
    "            alpha_hyper_hyper_scale=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5 / 0.01,\n",
    "            device='cpu',\n",
    "            lag=10,\n",
    "            lr=1e-0,\n",
    "            progress=False\n",
    "        ),\n",
    "        postclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "        ),\n",
    "        seed_sim=seed,\n",
    "        seed_fit=seed,\n",
    "        quiet=True,\n",
    "    )\n",
    "    results.append((seed, generr, comperr, scounter, entropy, runtime))\n",
    "    print(seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results1 = pd.DataFrame(results, columns=['seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    ax.hist(results1[stat])\n",
    "    ax.set_title(stat)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Benefits of increasing sample data (preclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n_fit in [20, 50, 100, 150, 200, 500]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=500,\n",
    "            g_sim=500,\n",
    "            n_fit=n_fit,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((n_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(n_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results2 = pd.DataFrame(results, columns=['n_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results2.set_index(['n_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Benefits of increasing sample data (no preclust, `s` known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n_fit in [20, 50, 100, 150, 200, 500]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=500,\n",
    "            g_sim=500,\n",
    "            n_fit=n_fit,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=20,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((n_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(n_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results3 = pd.DataFrame(results, columns=['n_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results3.set_index(['n_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4a: Benefits of increasing depth (no preclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in [0, 1, 3, 4, 5]:\n",
    "    for mu_hyper_mean_sim in reversed([0.5, 1., 2., 5., 10., 50., 1000.]):\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=mu_hyper_mean_sim,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=False,\n",
    "#             preclust_kwargs=dict(\n",
    "#                 thresh=0.1,\n",
    "#                 additional_strains_factor=0.1,\n",
    "#                 progress=False,\n",
    "#             ),\n",
    "            fit_kwargs=dict(\n",
    "                s=20,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5.,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results4a = pd.DataFrame(results, columns=['mu_hyper_mean_sim', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results4a.set_index(['mu_hyper_mean_sim', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('logit')\n",
    "        ax.set_ylim(1e-2, 5e-1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4b: Effects increasing depth (with preclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in [0, 1, 3, 4, 5]:\n",
    "    for mu_hyper_mean_sim in reversed([0.5, 1., 2., 5., 10., 50., 1000.]):\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=mu_hyper_mean_sim,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5.,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results4b = pd.DataFrame(results, columns=['mu_hyper_mean_sim', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results4b.set_index(['mu_hyper_mean_sim', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "    if stat == 'generr':\n",
    "        pass\n",
    "#         ax.set_yscale('logit')\n",
    "#         ax.set_ylim(1e-2, 5e-1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: Benefits of increasing genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for g_fit in [100, 250, 500, 1000, 2000]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 3, 4, 5, 8]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=2000,\n",
    "            n_fit=100,\n",
    "            g_fit=g_fit,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((g_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(g_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results5 = pd.DataFrame(results, columns=['g_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results5.set_index(['g_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 6: Strain-number estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for s_fit in [5, 10, 15, 20, 25, 30, 50]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=s_fit,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((s_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(s_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results6 = pd.DataFrame(results, columns=['s_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results6.set_index(['s_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7: Effects of genotype fuzzyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for gamma_hyper_fit in [1e-8, 1e-5, 1e-3, 1e-2, 5e-2, 1e-1, 5e-1]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=gamma_hyper_fit,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "                postclust_kwargs=dict(\n",
    "                    thresh=0.1,\n",
    "                ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((gamma_hyper_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(gamma_hyper_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results7 = pd.DataFrame(results, columns=['gamma_hyper_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results7.set_index(['gamma_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 8: Effects of diversity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for rho_hyper_fit in [1e-10, 0.0001, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=30,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=rho_hyper_fit,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((rho_hyper_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(rho_hyper_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results8 = pd.DataFrame(results, columns=['rho_hyper_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results8.set_index(['rho_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 9: Effects of heterogeneity regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in [0, 1, 3, 4, 5]:\n",
    "    for pi_hyper_fit in [1e-4, 1e-3, 1e-2, 5e-1, 1e0, 1e1, 1e2]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=10.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=pi_hyper_fit,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((pi_hyper_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(pi_hyper_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results9 = pd.DataFrame(results, columns=['pi_hyper_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results9.set_index(['pi_hyper_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 10: Effects of preclustering threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for preclust_thresh in [0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.2]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 6]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=preclust_thresh,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "\n",
    "        )\n",
    "        results.append((preclust_thresh, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(preclust_thresh, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results10 = pd.DataFrame(results, columns=['preclust_thresh', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results10.set_index(['preclust_thresh', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'comperr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 11: Effects of strain merging (postclustering) threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for postclust_thresh in [0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.2]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=1e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=postclust_thresh,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((postclust_thresh, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(postclust_thresh, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results11 = pd.DataFrame(results, columns=['postclust_thresh', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results11.set_index(['postclust_thresh', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'comperr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 12: Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for learning_rate in [0.05, 0.1, 0.5, 1., 1.5, 2.]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=learning_rate,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((learning_rate, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(learning_rate, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results12 = pd.DataFrame(results, columns=['learning_rate', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results12.set_index(['learning_rate', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 13: Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for delta_hyper_p_fit in [0.25, 0.5, 0.75, 0.9, 0.99, 1.]:\n",
    "    replicates = 0\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=20,\n",
    "            n_sim=100,\n",
    "            g_sim=500,\n",
    "            n_fit=100,\n",
    "            g_fit=500,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cpu'\n",
    "            ),\n",
    "            preclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "                additional_strains_factor=0.1,\n",
    "                progress=False,\n",
    "            ),\n",
    "            fit_kwargs=dict(\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=1.0,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=delta_hyper_p_fit,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cpu',\n",
    "                lag=10,\n",
    "                lr=2e-0,\n",
    "                progress=False\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((delta_hyper_p_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(delta_hyper_p_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results13 = pd.DataFrame(results, columns=['delta_hyper_p_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results13.set_index(['delta_hyper_p_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    ax.set_xscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Big matrix plot.\n",
    "\n",
    "all_results = [\n",
    "    (results2, 'n_fit', 'log', 2),\n",
    "    (results5, 'g_fit', 'log', 5),\n",
    "#     (results6, 's_fit', 'linear', 6),\n",
    "    (results4, 'mu_hyper_mean_sim', 'log', 4),\n",
    "]\n",
    "\n",
    "all_stats = [\n",
    "    ('generr', 'log'),\n",
    "    ('comperr', 'log'),\n",
    "    ('scounterr', 'linear'),\n",
    "    ('entropy', 'linear'),\n",
    "    ('runtime', 'log')\n",
    "]\n",
    "\n",
    "nres = len(all_results)\n",
    "nstat = len(all_stats)\n",
    "\n",
    "fig, axs = plt.subplots(nstat, nres, figsize=(3 * nres, 2 * nstat), sharex='col', sharey='row')\n",
    "\n",
    "for (stat, scale_y), row in zip(all_stats, axs):\n",
    "    for (results, indexer, scale_x, title), ax in zip(all_results, row):\n",
    "        results.set_index([indexer, 'seed'])[stat].unstack().plot(ax=ax)\n",
    "        ax.set_ylabel(stat)\n",
    "        ax.set_xlabel(indexer)\n",
    "        ax.legend_.set_visible(False)\n",
    "        ax.set_xscale(scale_x)\n",
    "        ax.set_yscale(scale_y)\n",
    "#        ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()\n",
    "#ax.legend(bbox_to_anchor=(1, 1), title='replicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Big matrix plot.\n",
    "\n",
    "all_results = [\n",
    "    (results2, 'n_fit', 'linear', 2),\n",
    "    (results5, 'g_fit', 'linear', 5),\n",
    "#     (results6, 's_fit', 'linear', 6),\n",
    "    (results4, 'mu_hyper_mean_sim', 'linear', 4),\n",
    "]\n",
    "\n",
    "all_stats = [\n",
    "    ('generr', 'linear'),\n",
    "    ('comperr', 'linear'),\n",
    "    ('scounterr', 'linear'),\n",
    "    ('entropy', 'linear'),\n",
    "    ('runtime', 'linear')\n",
    "]\n",
    "\n",
    "nres = len(all_results)\n",
    "nstat = len(all_stats)\n",
    "\n",
    "fig, axs = plt.subplots(nstat, nres, figsize=(3 * nres, 2 * nstat), sharex='col', sharey='row')\n",
    "\n",
    "for (stat, scale_y), row in zip(all_stats, axs):\n",
    "    for (results, indexer, scale_x, title), ax in zip(all_results, row):\n",
    "        results.set_index([indexer, 'seed'])[stat].unstack().plot(ax=ax)\n",
    "        ax.set_ylabel(stat)\n",
    "        ax.set_xlabel(indexer)\n",
    "        ax.legend_.set_visible(False)\n",
    "        ax.set_xscale(scale_x)\n",
    "        ax.set_yscale(scale_y)\n",
    "#        ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='replicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Big matrix plot.\n",
    "\n",
    "all_results = [\n",
    "    (results0, 'seed_fit', 'linear', 0),\n",
    "    (results2, 'n_fit', 'log', 2),\n",
    "    (results3, 'n_fit', 'log', 3),\n",
    "    (results4, 'mu_hyper_mean_sim', 'log', 4),\n",
    "    (results5, 'g_fit', 'log', 5),\n",
    "    (results6, 's_fit', 'linear', 6),\n",
    "    (results7, 'gamma_hyper_fit', 'log', 7),\n",
    "    (results8, 'rho_hyper_fit', 'log', 8),\n",
    "    (results9, 'pi_hyper_fit', 'log', 9),\n",
    "    (results10, 'preclust_thresh', 'linear', 10),\n",
    "    (results11, 'postclust_thresh', 'linear', 11),\n",
    "    (results12, 'learning_rate', 'log', 12),\n",
    "    (results13, 'delta_hyper_p_fit', 'logit', 13),\n",
    "]\n",
    "\n",
    "all_stats = [\n",
    "    ('generr', 'log'),\n",
    "    ('comperr', 'log'),\n",
    "    ('scounterr', 'symlog'),\n",
    "    ('entropy', 'linear'),\n",
    "    ('runtime', 'log')\n",
    "]\n",
    "\n",
    "nres = len(all_results)\n",
    "nstat = len*(all_stats)\n",
    "\n",
    "fig, axs = plt.subplots(nstat, nres, figsize=(2 * nres, 2 * nstat), sharex='col', sharey='row')\n",
    "\n",
    "for (stat, scale_y), row in zip(all_stats, axs):\n",
    "    for (results, indexer, scale_x, title), ax in zip(all_results, row):\n",
    "        results.set_index([indexer, 'seed'])[stat].unstack().plot(ax=ax)\n",
    "        ax.set_ylabel(stat)\n",
    "        ax.set_xlabel(indexer)\n",
    "        ax.legend_.set_visible(False)\n",
    "        ax.set_xscale(scale_x)\n",
    "        ax.set_yscale(scale_y)\n",
    "        ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo: Good accuracy with realistic conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed in range(20):\n",
    "    generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "        s_sim=20,\n",
    "        n_sim=200,\n",
    "        g_sim=1000,\n",
    "        n_fit=200,\n",
    "        g_fit=1000,\n",
    "        sim_kwargs=dict(\n",
    "            data=dict(\n",
    "                alpha_hyper_mean=100.\n",
    "            ),\n",
    "            gamma_hyper=0.01,\n",
    "            delta_hyper_temp=0.01,\n",
    "            delta_hyper_p=0.9,\n",
    "            pi_hyper=0.5,\n",
    "            rho_hyper=2.,\n",
    "            mu_hyper_mean=10.,\n",
    "            mu_hyper_scale=0.5,\n",
    "            m_hyper_r=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5/0.01,\n",
    "            device='cpu'\n",
    "        ),\n",
    "        preclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "            additional_strains_factor=0.1,\n",
    "            progress=False,\n",
    "        ),\n",
    "        fit_kwargs=dict(\n",
    "            gamma_hyper=0.01,\n",
    "            pi_hyper=1.0,\n",
    "            rho_hyper=0.5,\n",
    "            mu_hyper_mean=5,\n",
    "            mu_hyper_scale=5.,\n",
    "            m_hyper_r=10.,\n",
    "            delta_hyper_temp=0.1,\n",
    "            delta_hyper_p=0.9,\n",
    "            alpha_hyper_hyper_mean=100.,\n",
    "            alpha_hyper_hyper_scale=10.,\n",
    "            alpha_hyper_scale=0.5,\n",
    "            epsilon_hyper_alpha=1.5,\n",
    "            epsilon_hyper_beta=1.5 / 0.01,\n",
    "            device='cuda',\n",
    "            lag=10,\n",
    "            lr=2e-0,\n",
    "            progress=True\n",
    "        ),\n",
    "        postclust_kwargs=dict(\n",
    "            thresh=0.1,\n",
    "        ),\n",
    "        seed_sim=seed,\n",
    "        seed_fit=seed,\n",
    "        quiet=True,\n",
    "    )\n",
    "    results.append((seed, generr, comperr, scounter, entropy, runtime))\n",
    "    print(seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results_d0 = pd.DataFrame(results, columns=['seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    ax.hist(results_d0[stat], bins=5)\n",
    "    ax.set_title(stat)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}