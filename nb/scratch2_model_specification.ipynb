{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.util import info, idxwhere\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "import arviz as az\n",
    "from pyro.ops.contract import einsum\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegativeBinomialReparam(mu, r):\n",
    "    p = 1 / ((r / mu) + 1)\n",
    "    return dist.NegativeBinomial(\n",
    "        total_count=r,\n",
    "        probs=p\n",
    "    )\n",
    "\n",
    "def as_torch(x, dtype=torch.float32, device=\"cpu\"):\n",
    "    return torch.tensor(x, dtype=dtype, device=device)\n",
    "\n",
    "def all_torch(dtype=torch.float32, device=\"cpu\", **kwargs):\n",
    "    # Cast inputs and set device\n",
    "    return {k: as_torch(kwargs[k], dtype=dtype, device=device) for k in kwargs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2: Gumbel-Softmax with missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=as_torch(1.),\n",
    "    delta_temp=as_torch(1.),\n",
    "    delta_p=as_torch(0.9),\n",
    "    rho_hyper=as_torch(1.),\n",
    "    pi_hyper=as_torch(1.),\n",
    "    mu_hyper_mean=as_torch(10.),\n",
    "    mu_hyper_scale=as_torch(0.5),\n",
    "    m_hyper=as_torch(1.),\n",
    "    epsilon_hyper=as_torch(0.01),\n",
    "    alpha_hyper=as_torch(100.),\n",
    "):\n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            # Allele\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, probs=torch.tensor(0.5))\n",
    "            )\n",
    "            # Position presence/absence\n",
    "            delta = pyro.sample(\n",
    "                'delta', dist.RelaxedBernoulli(temperature=delta_temp, probs=delta_p)\n",
    "            )\n",
    "    \n",
    "    # Meta-community strain composition\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s)))\n",
    "    \n",
    "    alpha = pyro.sample('alpha', dist.Gamma(alpha_hyper, 1.)).unsqueeze(-1)\n",
    "    \n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        # Strain composition.\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        # Overdispersion of observations\n",
    "        # Error rate\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        # Fold coverage\n",
    "        mu = pyro.sample('mu', dist.LogNormal(loc=torch.log(mu_hyper_mean), scale=mu_hyper_scale))\n",
    "\n",
    "    \n",
    "    # Expected fractions of each allele at each position\n",
    "    nu = pyro.deterministic(\"nu\", pi @ delta)\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ (gamma * delta) / nu)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    \n",
    "    # Depth at each position\n",
    "    m = pyro.sample('m', NegativeBinomialReparam(nu * mu.reshape((-1,1)), m_hyper))\n",
    "        \n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "#     y = pyro.sample(\n",
    "#         'y',\n",
    "#         dist.Binomial(\n",
    "#             probs=p,\n",
    "#             total_count=m\n",
    "#         ),\n",
    "#     )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, g, s = 100, 200, 30\n",
    "\n",
    "model2_sim = partial(\n",
    "    pyro.condition(\n",
    "        model2,\n",
    "        data=all_torch(),\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **all_torch(\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.1,\n",
    "        rho_hyper=2.,\n",
    "        delta_temp=0.001,\n",
    "        m_hyper=5,\n",
    "        mu_hyper_mean=10,\n",
    "        mu_hyper_scale=0.5,\n",
    "    )\n",
    ")\n",
    "\n",
    "trace = pyro.poutine.trace(model2_sim).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = pyro.infer.Predictive(model2_sim, num_samples=1)()\n",
    "sim2 = {k: sim2[k].detach().cpu().numpy().squeeze() for k in sim2.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, figsize=(5, 10))\n",
    "\n",
    "sns.heatmap(sim2['delta'], ax=axs[0], vmin=0, vmax=1)\n",
    "sns.heatmap(sim2['pi'].T, ax=axs[1], vmin=0, vmax=1)\n",
    "sns.heatmap(sim2['nu'], ax=axs[2], vmin=0, vmax=1)\n",
    "sns.heatmap(sim2['m'], ax=axs[3], vmin=0, norm=mpl.colors.PowerNorm(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_fit = partial(\n",
    "    pyro.condition(\n",
    "        model2,\n",
    "        data=all_torch(m=sim2['m'], y=sim2['y'])\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **all_torch(\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.1,\n",
    "        rho_hyper=0.05,\n",
    "        delta_temp=0.5,\n",
    "        alpha_hyper=100.,\n",
    "        m_hyper=5,\n",
    "        mu_hyper_mean=10,\n",
    "        mu_hyper_scale=2,\n",
    "    )\n",
    ")\n",
    "\n",
    "_guide = pyro.infer.autoguide.AutoLaplaceApproximation(model2_fit)\n",
    "opt = pyro.optim.Adamax({\"lr\": 1e-0}, {\"clip_norm\": 100.})\n",
    "svi = pyro.infer.SVI(\n",
    "    model2_fit,\n",
    "    _guide,\n",
    "    opt,\n",
    "    loss=pyro.infer.Trace_ELBO()\n",
    ")\n",
    "pyro.clear_param_store()\n",
    "\n",
    "n_iter = int(1e4)\n",
    "lag = 100\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(n_iter))\n",
    "try:\n",
    "    for i in pbar:\n",
    "        elbo = svi.step()\n",
    "        if np.isnan(elbo):\n",
    "            print(\"ELBO = NaN\")\n",
    "            break\n",
    "        history.append(elbo)\n",
    "\n",
    "        # Reporting/Breaking\n",
    "        if (i % 1 == 0):\n",
    "            if i > lag:\n",
    "                delta_lag = (history[-lag] - history[-1]) / lag\n",
    "                pbar.set_postfix({\n",
    "                    'ELBO': history[-1],\n",
    "                    'delta': history[-2] - history[-1],\n",
    "                    f'lag{lag}': delta_lag,\n",
    "                })\n",
    "                if delta_lag < 0:\n",
    "                    print(f\"Converged: {elbo}\")\n",
    "                    elbo = svi.step()\n",
    "                    break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "finally:\n",
    "    pbar.refresh()\n",
    "    est2 = pyro.infer.Predictive(model2_fit, guide=_guide, num_samples=1)()\n",
    "    est2 = {k: est2[k].detach().cpu().numpy().mean(axis=0).squeeze() for k in est2.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gamma = pd.concat([\n",
    "    pd.DataFrame(sim2['gamma'], index=[f'sim_{i}' for i in range(len(sim2['gamma']))]),\n",
    "    pd.DataFrame(est2['gamma'], index=[f'est_{i}' for i in range(len(est2['gamma']))]),\n",
    "])\n",
    "\n",
    "sns.clustermap(combined_gamma.T * 2 - 1, vmin=-1, vmax=1, cmap='coolwarm', metric='cosine', xticklabels=1)\n",
    "#sns.heatmap(est2['gamma'] * 2 - 1, ax=axs[1], vmin=-1, vmax=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pi = pd.concat([\n",
    "    pd.DataFrame(sim2['pi'].T, index=[f'sim_{i}' for i in range(len(sim2['pi'].T))]),\n",
    "    pd.DataFrame(est2['pi'].T, index=[f'est_{i}' for i in range(len(est2['pi'].T))]),\n",
    "])\n",
    "\n",
    "sns.clustermap(combined_pi.T, vmin=0, vmax=1, metric='cosine', xticklabels=1)\n",
    "#sns.heatmap(est2['gamma'] * 2 - 1, ax=axs[1], vmin=-1, vmax=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_delta = pd.concat([\n",
    "    pd.DataFrame(sim2['delta'], index=[f'sim_{i}' for i in range(len(sim2['delta']))]),\n",
    "    pd.DataFrame(est2['delta'], index=[f'est_{i}' for i in range(len(est2['delta']))]),\n",
    "])\n",
    "\n",
    "sns.clustermap(combined_delta.T, vmin=0, vmax=1, metric='cosine', xticklabels=1)\n",
    "#sns.heatmap(est2['gamma'] * 2 - 1, ax=axs[1], vmin=-1, vmax=1, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim2['mu'], est2['mu'], c=sim2['m'].mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim2['epsilon'], est2['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim2['alpha'], est2['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model0: Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model0(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=as_torch(1.),\n",
    "    rho_hyper=as_torch(1.),\n",
    "    pi_hyper=as_torch(1.),\n",
    "    m_hyper_mu=as_torch(10.),\n",
    "    m_hyper_r=as_torch(1.),\n",
    "    epsilon_hyper=as_torch(0.01),\n",
    "    alpha_hyper=as_torch(100.),\n",
    "):\n",
    "    \n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.Beta(gamma_hyper, gamma_hyper)\n",
    "            )\n",
    "    \n",
    "#     rho_ = pyro.sample('rho_', dist.LogNormal(0, 1 / rho_hyper).expand([s]).to_event())\n",
    "#     rho = pyro.deterministic('rho', rho_ / rho_.sum())\n",
    "    rho = pyro.sample('rho', dist.Dirichlet(torch.ones(s) * rho_hyper))\n",
    "    \n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        pi = pyro.sample('pi', dist.Dirichlet(rho * pi_hyper * s))\n",
    "        alpha = pyro.sample('alpha', dist.Gamma(alpha_hyper, 1.)).unsqueeze(-1)\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        \n",
    "    m = pyro.sample('m', NegativeBinomialReparam(m_hyper_mu, m_hyper_r).expand([n, g]))\n",
    "\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ gamma)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "        \n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ),\n",
    "    )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, g, s = 500, 1000, 100\n",
    "\n",
    "model0_sim = partial(\n",
    "    pyro.condition(\n",
    "        model0,\n",
    "        data={\n",
    "        },\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **as_torch(\n",
    "        gamma_hyper=0.1,\n",
    "        pi_hyper=0.001,\n",
    "        rho_hyper=1.,\n",
    "    )\n",
    ")\n",
    "\n",
    "trace = pyro.poutine.trace(model0_sim).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pyro.infer.Predictive(model0_sim, num_samples=1)()\n",
    "sim = {k: sim[k].detach().cpu().numpy().squeeze() for k in sim.keys()}\n",
    "\n",
    "sns.heatmap(sim['pi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(sim['rho']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "# pi_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "# rho_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "\n",
    "\n",
    "model0_fit = partial(\n",
    "    pyro.condition(\n",
    "        model0,\n",
    "        data={\n",
    "            'm': torch.tensor(sim['m']),\n",
    "            'y': torch.tensor(sim['y']),\n",
    "        },\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **as_torch(\n",
    "        pi_hyper=1.0,\n",
    "        rho_hyper=1.0,\n",
    "        gamma_hyper=1.0,\n",
    "    )\n",
    ")\n",
    "\n",
    "_guide = pyro.infer.autoguide.AutoLaplaceApproximation(model0_fit)\n",
    "opt = pyro.optim.Adamax({\"lr\": 1e-0}, {\"clip_norm\": 100.})\n",
    "svi = pyro.infer.SVI(\n",
    "    model0_fit,\n",
    "    _guide,\n",
    "    opt,\n",
    "    loss=pyro.infer.JitTrace_ELBO()\n",
    ")\n",
    "pyro.clear_param_store()\n",
    "\n",
    "n_iter = int(5e2)\n",
    "# step_hypers_at = int(5e2)\n",
    "# start_pi_shift_at = int(5e3)\n",
    "# pi_hyper_schedule = np.concatenate([\n",
    "#     np.logspace(0.01, 0, start_pi_shift_at // step_hypers_at),\n",
    "#     np.logspace(0, -1.0, (n_iter - start_pi_shift_at) // step_hypers_at),\n",
    "# ]).astype('float32')\n",
    "# rho_hyper_schedule = np.logspace(0, -2, num=n_iter // step_hypers_at).astype('float32')\n",
    "# gamma_hyper_schedule = np.logspace(0, -2, num=n_iter // step_hypers_at).astype('float32')\n",
    "# plt.scatter(rho_hyper_schedule, pi_hyper_schedule, c=np.linspace(0, 1, num=pi_hyper_schedule.shape[0]))\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(n_iter))\n",
    "for i in pbar:\n",
    "#     pi_hyper_fit.data = torch.tensor(pi_hyper_schedule[i // step_hypers_at])\n",
    "#     rho_hyper_fit.data = torch.tensor(rho_hyper_schedule[i // step_hypers_at])\n",
    "#     gamma_hyper_fit.data = torch.tensor(gamma_hyper_schedule[i // step_hypers_at])\n",
    "#     pi_hyper_fit.data = torch.tensor(1.)\n",
    "#     rho_hyper_fit.data = torch.tensor(1.)\n",
    "#     gamma_hyper_fit.data = torch.tensor(1.)\n",
    "\n",
    "    elbo = svi.step()\n",
    "    \n",
    "    if np.isnan(elbo):\n",
    "        break\n",
    "\n",
    "    # Fit tracking\n",
    "    history.append(elbo)\n",
    "    \n",
    "    # Reporting/Breaking\n",
    "    if (i % 1 == 0):\n",
    "        if i > 1:\n",
    "            pbar.set_postfix({\n",
    "                'ELBO': history[-1],\n",
    "                'delta': history[-2] - history[-1],\n",
    "#                 'pi_hyper': pi_hyper_fit,\n",
    "#                 'rho_hyper': rho_hyper_fit,\n",
    "#                 'gamma_hyper': gamma_hyper_fit,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = pyro.infer.Predictive(model0_fit, guide=_guide, num_samples=1)()\n",
    "est = {k: est[k].detach().cpu().numpy().squeeze() for k in sim.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(est['pi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(est['gamma'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(est['rho']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: Gumbel-Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=torch.tensor(1.),\n",
    "    rho_hyper=torch.tensor(1.),\n",
    "    pi_hyper=torch.tensor(1.),\n",
    "    m_hyper_mu=torch.tensor(10.),\n",
    "    m_hyper_r=torch.tensor(1.),\n",
    "    epsilon_hyper=torch.tensor(0.01),\n",
    "    alpha_hyper=torch.tensor(100.),\n",
    "):\n",
    "    \n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, probs=torch.tensor(0.5))\n",
    "            )\n",
    "    \n",
    "#     rho_ = pyro.sample('rho_', dist.LogNormal(0, 1 / rho_hyper).expand([s]).to_event())\n",
    "#     rho = pyro.deterministic('rho', rho_ / rho_.sum())\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s)))\n",
    "    \n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        alpha = pyro.sample('alpha', dist.Gamma(alpha_hyper, 1.)).unsqueeze(-1)\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        \n",
    "    m = pyro.sample('m', NegativeBinomialReparam(m_hyper_mu, m_hyper_r).expand([n, g]))\n",
    "\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ gamma)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "        \n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ),\n",
    "    )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, g, s = 500, 1000, 100\n",
    "\n",
    "model1_sim = partial(\n",
    "    pyro.condition(\n",
    "        model1,\n",
    "        data={\n",
    "        },\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **as_torch(\n",
    "        gamma_hyper=0.1,\n",
    "        pi_hyper=0.1,\n",
    "        rho_hyper=1.,\n",
    "    )\n",
    ")\n",
    "\n",
    "trace = pyro.poutine.trace(model1_sim).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Comment out this cell to have data simulated by model0 instead.\n",
    "\n",
    "sim = pyro.infer.Predictive(model1_sim, num_samples=1)()\n",
    "sim = {k: sim[k].detach().cpu().numpy().squeeze() for k in sim.keys()}\n",
    "\n",
    "plt.plot(np.sort(sim['rho']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "# pi_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "# rho_hyper_fit = torch.autograd.Variable(torch.tensor(1.))\n",
    "\n",
    "\n",
    "model1_fit = partial(\n",
    "    pyro.condition(\n",
    "        model1,\n",
    "        data={\n",
    "            'm': torch.tensor(sim['m']),\n",
    "            'y': torch.tensor(sim['y']),\n",
    "        },\n",
    "    ),\n",
    "    s=s,\n",
    "    g=g,\n",
    "    n=n,\n",
    "    **as_torch(\n",
    "        gamma_hyper=1.,\n",
    "        pi_hyper=1.,\n",
    "        rho_hyper=1.,\n",
    "    )\n",
    ")\n",
    "\n",
    "_guide = pyro.infer.autoguide.AutoLaplaceApproximation(model1_fit)\n",
    "opt = pyro.optim.Adamax({\"lr\": 1e-0}, {\"clip_norm\": 100.})\n",
    "svi = pyro.infer.SVI(\n",
    "    model1_fit,\n",
    "    _guide,\n",
    "    opt,\n",
    "    loss=pyro.infer.JitTrace_ELBO()\n",
    ")\n",
    "pyro.clear_param_store()\n",
    "\n",
    "n_iter = int(5e2)\n",
    "# step_hypers_at = int(5e2)\n",
    "# start_pi_shift_at = int(5e3)\n",
    "# pi_hyper_schedule = np.concatenate([\n",
    "#     np.logspace(0.01, 0, start_pi_shift_at // step_hypers_at),\n",
    "#     np.logspace(0, -1.0, (n_iter - start_pi_shift_at) // step_hypers_at),\n",
    "# ]).astype('float32')\n",
    "# rho_hyper_schedule = np.logspace(0, -2, num=n_iter // step_hypers_at).astype('float32')\n",
    "# gamma_hyper_schedule = np.logspace(0, -2, num=n_iter // step_hypers_at).astype('float32')\n",
    "# plt.scatter(rho_hyper_schedule, pi_hyper_schedule, c=np.linspace(0, 1, num=pi_hyper_schedule.shape[0]))\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(n_iter))\n",
    "for i in pbar:\n",
    "#     pi_hyper_fit.data = torch.tensor(pi_hyper_schedule[i // step_hypers_at])\n",
    "#     rho_hyper_fit.data = torch.tensor(rho_hyper_schedule[i // step_hypers_at])\n",
    "#     gamma_hyper_fit.data = torch.tensor(gamma_hyper_schedule[i // step_hypers_at])\n",
    "#     pi_hyper_fit.data = torch.tensor(1.)\n",
    "#     rho_hyper_fit.data = torch.tensor(1.)\n",
    "#     gamma_hyper_fit.data = torch.tensor(1.)\n",
    "\n",
    "    elbo = svi.step()\n",
    "    \n",
    "    if np.isnan(elbo):\n",
    "        break\n",
    "\n",
    "    # Fit tracking\n",
    "    history.append(elbo)\n",
    "    \n",
    "    # Reporting/Breaking\n",
    "    if (i % 1 == 0):\n",
    "        if i > 1:\n",
    "            pbar.set_postfix({\n",
    "                'ELBO': history[-1],\n",
    "                'delta': history[-2] - history[-1],\n",
    "#                 'pi_hyper': pi_hyper_fit,\n",
    "#                 'rho_hyper': rho_hyper_fit,\n",
    "#                 'gamma_hyper': gamma_hyper_fit,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = pyro.infer.Predictive(model1_fit, guide=_guide, num_samples=1)()\n",
    "est = {k: est[k].detach().cpu().numpy().squeeze() for k in sim.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(est['rho']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(est['pi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(est['gamma'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(est['rho']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}