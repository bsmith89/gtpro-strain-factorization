{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfacts.data import load_input_data, select_informative_positions\n",
    "import numpy as np\n",
    "from sfacts.logging_util import info\n",
    "from sfacts.pandas_util import idxwhere\n",
    "from sfacts.workflow import fit_to_data\n",
    "import sfacts as sf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.spatial.distance import braycurtis, cosine, pdist\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from lib.plot import rotate_xticklabels\n",
    "\n",
    "\n",
    "def linear_distance(linear_index):\n",
    "    linear_index = linear_index.to_frame()\n",
    "    return pd.DataFrame(\n",
    "        squareform(\n",
    "            pdist(\n",
    "                linear_index,\n",
    "                metric='cityblock'\n",
    "            )\n",
    "        ),\n",
    "        index=linear_index.index,\n",
    "        columns=linear_index.index,\n",
    "    )\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import ordination_plot\n",
    "from lib.pandas import align_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\",\n",
    "    category=torch.jit.TracerWarning,\n",
    "#     module=\"trace_elbo\",  # FIXME: What is the correct regex for module?\n",
    "#     lineno=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_position_meta_ = pd.read_table(\n",
    "    '/pollard/data/gt-pro-db/variants_main.covered.hq.snp_dict.tsv',\n",
    "    names=['species_id', 'position', 'contig', 'contig_position', 'ref', 'alt']\n",
    ").set_index('position')\n",
    "all_species_position_meta_ = all_species_position_meta_[all_species_position_meta_.species_id.isin([100022, 102506])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_position_meta_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta = pd.read_table('raw/shi2019s13.tsv').set_index('NCBI Accession Number')\n",
    "sample_meta.groupby(['Study', 'Continent']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_studies = ['CM_madagascar', 'Bengtsson-PalmeJ_2015', 'FengQ_2015', 'LiJ_2017', 'LomanNJ_2013']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All MGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 102506 (Escherichia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(\"Loading input data.\")\n",
    "data = load_input_data(['data/core.sp-102506.gtpro-pileup.nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_ss, data_fit, history = sf.workflow.filter_subsample_and_fit(\n",
    "    data,\n",
    "    incid_thresh=0.1,\n",
    "    cvrg_thresh=0.05,\n",
    "    npos=1000,\n",
    "    preclust=False,\n",
    "#     preclust_kwargs=dict(\n",
    "#         thresh=0.1,\n",
    "#         additional_strains_factor=0.,\n",
    "#         progress=True,\n",
    "#     ),\n",
    "    fit_kwargs=dict(\n",
    "        s=400,\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.01,\n",
    "        rho_hyper=0.5,\n",
    "        mu_hyper_mean=5,\n",
    "        mu_hyper_scale=5.,\n",
    "        m_hyper_r=10.,\n",
    "        delta_hyper_temp=0.1,\n",
    "        delta_hyper_p=0.9,\n",
    "        alpha_hyper_hyper_mean=100.,\n",
    "        alpha_hyper_hyper_scale=10.,\n",
    "        alpha_hyper_scale=0.5,\n",
    "#         alpha_hyper_hyper_mean=10000.,\n",
    "#         alpha_hyper_hyper_scale=0.001,\n",
    "#         alpha_hyper_scale=0.001,\n",
    "        epsilon_hyper_alpha=1.5,\n",
    "        epsilon_hyper_beta=1.5 / 0.01,\n",
    "        device='cuda',\n",
    "        lag=100,\n",
    "        lr=1e-1,\n",
    "        progress=True\n",
    "    ),\n",
    "    postclust_kwargs=dict(\n",
    "        thresh=0.1,\n",
    "        progress=True,\n",
    "    ),\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(mrg_ss['alpha']), bins=100)\n",
    "#plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(mrg_ss['epsilon']), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_strains = (mrg_ss['pi'] > 0.75).sum(0).argsort()[-50:]\n",
    "top_samples = ((mrg_ss['pi'][:,top_strains] > 0.25).sum(1)).argsort()[-100:]\n",
    "\n",
    "sf.plot.plot_community(\n",
    "    mrg_ss['pi'][top_samples][:, top_strains],\n",
    "    yticklabels=1,\n",
    "    row_colors=mpl.cm.viridis(np.log10(mrg_ss['alpha'][top_samples])),\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    "    norm=mpl.colors.PowerNorm(1/3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sf.plot.plot_genotype(\n",
    "    sf.genotype.mask_missing_genotype(mrg_ss['gamma'], mrg_ss['delta']), scalex=0.06, scaley=0.01, dheight=4, dwidth=0.2, xticklabels=0, tree_kws=dict(lw=1),\n",
    "#     col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sf.plot.plot_genotype(\n",
    "    mrg_ss['gamma'][top_strains],\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sf.plot.plot_missing(\n",
    "    mrg_ss['delta'][top_strains],\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_estimate = sf.genotype.counts_to_p_estimate(\n",
    "    data_fit.sel(allele='alt'), data_fit.sum('allele')\n",
    ")\n",
    "\n",
    "#sf.plot.plot_genotype(p_estimate.values[top_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biogeography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct composition matrix for samples with biogeography data\n",
    "\n",
    "composition = pd.DataFrame(mrg_ss['pi'], index=data_fit.library_id)\n",
    "meta = sample_meta.reindex(composition.index).dropna(subset=['Sample ID'])\n",
    "composition_bg = composition.reindex(meta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = composition_bg[meta['Study'].isin(['VatanenT_2016'])]\n",
    "strains = idxwhere((composition_bg[meta['Study'].isin(['VatanenT_2016'])] > 0.5).sum() > 1)\n",
    "\n",
    "sf.plot.plot_community(\n",
    "    d.loc[:, strains],\n",
    "    yticklabels=1,\n",
    "    norm=mpl.colors.PowerNorm(1/3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This is a giant contingency table,\n",
    "# and the p-value on a chisq test shows clearly that strains clump\n",
    "# into countries.\n",
    "\n",
    "contingency = (\n",
    "    composition_bg\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency = (\n",
    "    composition_bg\n",
    "    .set_index(composition_bg.sample(frac=1.0).index)\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same analysis, but carefully selecting studies that I don't believe have\n",
    "# multiple metagenomes from same/related individuals.\n",
    "\n",
    "contingency2 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency2 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .set_index(composition_bg[meta['Study'].isin(select_studies)].sample(frac=1.0).index)\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency2)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same analysis, but carefully selecting studies that I don't believe have\n",
    "# multiple metagenomes from same/related individuals.\n",
    "# And clustering by study rather than country.\n",
    "\n",
    "contingency3 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .groupby(meta['Study'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency3 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .set_index(composition_bg[meta['Study'].isin(select_studies)].sample(frac=1.0).index)\n",
    "    .groupby(meta['Study'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency3)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['Study'].isin(select_studies)].groupby('Study').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta[meta['Study'].isin(select_studies)].groupby('Country').apply(len)\n",
    "\n",
    "top_20_strains = contingency2.apply(lambda x: x / x.sum(), axis=1).mean().sort_values(ascending=False).head(20).index\n",
    "\n",
    "ax = (\n",
    "    contingency2\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .loc[['CHN', 'MDG', 'AUT', 'DEU', 'SWE'], top_20_strains]\n",
    "    .plot\n",
    "    .bar(stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)))\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top 20 Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.groupby(['Study', 'Country']).apply(len).unstack(fill_value=0).loc[select_studies].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta[meta['Study'].isin(select_studies)].groupby('Country').apply(len)\n",
    "\n",
    "top_20_strains = contingency3.apply(lambda x: x / x.sum(), axis=1).mean().sort_values(ascending=False).head(20).index\n",
    "\n",
    "ax = (\n",
    "    contingency3\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .loc[:, top_20_strains]\n",
    "    .plot\n",
    "    .bar(stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)))\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top 20 Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta.groupby([meta['Continent'], meta['Country'], meta['Study']]).apply(len)\n",
    "\n",
    "d = (\n",
    "    composition_bg\n",
    "    .groupby([meta['Continent'], meta['Country'], meta['Study']])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    ")\n",
    "top_strains = d.mean().sort_values(ascending=False).head(15).index\n",
    "\n",
    "d = d.loc[:, top_strains].assign(other=1 - d.loc[:, top_strains].sum(1)).drop(idxwhere(count_individuals < 10))\n",
    "\n",
    "ax = (\n",
    "    d\n",
    "    .plot\n",
    "    .bar(\n",
    "        stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)),\n",
    "        figsize=(10, 5)\n",
    "    )\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')\n",
    "rotate_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pairs = pd.read_table('raw/shi2019s14.tsv').set_index(['Sample Run 1', 'Sample Run 2'])\n",
    "\n",
    "bc_dist = {}\n",
    "cos_dist = {}\n",
    "\n",
    "for libraryA, libraryB in tqdm(sample_pairs.index):\n",
    "    if (libraryA not in composition_bg.index) or (libraryB not in composition_bg.index):\n",
    "        continue\n",
    "    bc_dist[(libraryA, libraryB)] = braycurtis(composition_bg.loc[libraryA], composition_bg.loc[libraryB])\n",
    "    cos_dist[(libraryA, libraryB)] = cosine(p_estimate.loc[libraryA], p_estimate.loc[libraryB])\n",
    "\n",
    "sample_pairs = sample_pairs.assign(bc=pd.Series(bc_dist), cos=pd.Series(cos_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot('Group Type', 'bc', data=sample_pairs, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot('Group Type', 'cos', data=sample_pairs, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('cos', 'bc', data=sample_pairs, kind='hex', norm=mpl.colors.PowerNorm(1/5))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cos_cdmat = pdist(p_estimate, metric='cosine')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bc_cdmat = pdist(mrg_ss['pi'], metric='braycurtis')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.jointplot(x='cos', y='bc', data=pd.DataFrame(dict(cos=cos_cdmat, bc=bc_cdmat)), kind='hex', norm=mpl.colors.PowerNorm(1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rarefaction = []\n",
    "strain_counts = defaultdict(lambda: 0)\n",
    "for strain_id in composition_bg.idxmax(1).sample(frac=1.0).values:\n",
    "    strain_counts[strain_id] += 1\n",
    "    rarefaction.append(len(strain_counts))\n",
    "rarefaction = np.array(rarefaction)\n",
    "\n",
    "plt.plot(rarefaction)\n",
    "plt.plot([0, 400], [0, 400], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_incidence = (composition_bg > 1e-1).sum()\n",
    "\n",
    "observed_total = len(strain_incidence)\n",
    "observed_singletons = (strain_incidence == 1).sum()\n",
    "observed_doubletons = (strain_incidence == 2).sum()\n",
    "\n",
    "chao2 = observed_total + ((observed_singletons**2) / (2 * observed_doubletons))\n",
    "print(chao2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "rarefaction = []\n",
    "strain_counts = defaultdict(lambda: 0)\n",
    "for strain_id in composition.idxmax(1).sample(frac=1.0).values:\n",
    "    strain_counts[strain_id] += 1\n",
    "    rarefaction.append(len(strain_counts))\n",
    "rarefaction = np.array(rarefaction)\n",
    "\n",
    "plt.plot(rarefaction)\n",
    "plt.plot([0, 250], [0, 250], lw=1, linestyle='--', color='k')\n",
    "\n",
    "plt.ylabel('Observed genotype clusters')\n",
    "plt.xlabel('Number of samples')\n",
    "plt.title(\"Escherichia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_incidence = (composition > 1e-1).sum()\n",
    "\n",
    "observed_total = len(strain_incidence)\n",
    "observed_singletons = (strain_incidence == 1).sum()\n",
    "observed_doubletons = (strain_incidence == 2).sum()\n",
    "\n",
    "chao2 = observed_total + ((observed_singletons**2) / (2 * observed_doubletons))\n",
    "print(chao2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est, data_filt, informative_positions, position_ss = sf.workflow.filter_subsample_fit_and_refit_genotypes(\n",
    "    data,\n",
    "    incid_thresh=0.1,\n",
    "    cvrg_thresh=0.05,\n",
    "    npos=1000,\n",
    "    preclust=False,\n",
    "#     preclust_kwargs=dict(\n",
    "#         thresh=0.1,\n",
    "#         additional_strains_factor=0.,\n",
    "#         progress=True,\n",
    "#     ),\n",
    "    fit_kwargs=dict(\n",
    "        s=400,\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.01,\n",
    "        rho_hyper=0.5,\n",
    "        mu_hyper_mean=5,\n",
    "        mu_hyper_scale=5.,\n",
    "        m_hyper_r=10.,\n",
    "        delta_hyper_temp=0.1,\n",
    "        delta_hyper_p=0.9,\n",
    "        alpha_hyper_hyper_mean=100.,\n",
    "        alpha_hyper_hyper_scale=10.,\n",
    "        alpha_hyper_scale=0.5,\n",
    "#         alpha_hyper_hyper_mean=10000.,\n",
    "#         alpha_hyper_hyper_scale=0.001,\n",
    "#         alpha_hyper_scale=0.001,\n",
    "        epsilon_hyper_alpha=1.5,\n",
    "        epsilon_hyper_beta=1.5 / 0.01,\n",
    "        device='cuda',\n",
    "        lag=100,\n",
    "        lr=1e-1,\n",
    "        progress=True\n",
    "    ),\n",
    "    postclust_kwargs=dict(\n",
    "        thresh=0.1,\n",
    "        progress=True,\n",
    "    ),\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "pickle.dump(est, open('data/core.sp-102506.gtpro-pileup.sf-est.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "composition = pd.DataFrame(est['pi'], index=data_filt.library_id)\n",
    "meta = pd.read_table('raw/shi2019s13.tsv').set_index('NCBI Accession Number').reindex(composition.index).dropna(subset=['Sample ID'])\n",
    "composition = composition.reindex(meta.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est['gamma'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_genotype(est['gamma'][:,:100], row_cluster=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "npos = 10000\n",
    "\n",
    "sf.plot.plot_genotype(\n",
    "    sf.genotype.mask_missing_genotype(\n",
    "        est['gamma'][:,:npos],\n",
    "        est['delta'][:,:npos]\n",
    "    ),\n",
    "    scalex=0.05,\n",
    "    scaley=0.001,\n",
    "    dheight=2.5,\n",
    "    xticklabels=0,\n",
    "#     row_cluster=False,\n",
    "    tree_kws=dict(lw=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est['gamma'].mean(0), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((est['pi'] @ est['gamma']).mean(0), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_meta = all_species_position_meta_[lambda x: x.species_id == 102506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_meta.loc[informative_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def pos_psim(gamma, delta):\n",
    "    gamma_ = sf.genotype.mask_missing_genotype(gamma, delta)\n",
    "    return (1 - squareform(pdist((gamma_.T), metric='correlation')))**2\n",
    "\n",
    "position_sim = pd.DataFrame(pos_psim(est['gamma'], est['delta']), index=informative_positions, columns=informative_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - squareform(1 - position_sim)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_info = (\n",
    "    position_meta\n",
    "    .groupby('contig')\n",
    "    .apply(len)\n",
    "    .to_frame(name='total_count')\n",
    "    .assign(\n",
    "        fit_count=position_meta.loc[informative_positions]\n",
    "        .groupby('contig')\n",
    "        .apply(len)\n",
    "    ).fillna(0)\n",
    ").sort_values('fit_count', ascending=False)\n",
    "\n",
    "snp_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ldist_ = linear_distance(\n",
    "    position_meta.loc[informative_positions]['contig_position']\n",
    ").sort_index().sort_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "same_contig = pd.DataFrame(\n",
    "    1 - squareform(\n",
    "        pdist(\n",
    "            patsy.dmatrix(\n",
    "                'contig - 1', data=position_meta.loc[informative_positions]['contig'].to_frame(), return_type='dataframe'\n",
    "            ),\n",
    "            'jaccard'),\n",
    "    ),\n",
    "    index=informative_positions, columns=informative_positions,\n",
    "\n",
    ")\n",
    "#sns.heatmap(same_contig.sort_index().sort_index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_data = pd.DataFrame(dict(\n",
    "    linear_distance=squareform(position_ldist_.values),\n",
    "    same_contig=(squareform(1 - same_contig.values) == 0),\n",
    "    ld=1 - squareform(1 - position_sim),\n",
    "))\n",
    "ld_data = ld_data[ld_data.same_contig]\n",
    "ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ld_data[\n",
    "        lambda x: x.same_contig & (150 < x.linear_distance) & (x.linear_distance < 2000)\n",
    "]\n",
    "\n",
    "plt.scatter(\n",
    "    x='linear_distance',\n",
    "    y='ld',\n",
    "    data=d,\n",
    "    s=1,\n",
    "    alpha=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\n",
    "    x='linear_distance',\n",
    "    y='ld',\n",
    "    data=ld_data[\n",
    "        lambda x: x.same_contig & (0 < x.linear_distance) & (x.linear_distance < 2000)\n",
    "    ],\n",
    "    kind='hex',\n",
    "    norm=mpl.colors.PowerNorm(1/3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_data[\n",
    "        lambda x: x.same_contig & (0 < x.linear_distance) & (x.linear_distance < 100)\n",
    "    ].ld.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_data[\n",
    "        lambda x: x.same_contig & (100 < x.linear_distance) & (x.linear_distance < 200)\n",
    "    ].ld.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsize = 25\n",
    "right = 5000\n",
    "\n",
    "d = ld_data[ld_data.linear_distance < right]\n",
    "\n",
    "bins = {}\n",
    "for start in range(0, right, stepsize):\n",
    "    stop = start + stepsize\n",
    "    bins[start] = d[(d.linear_distance >= start) & (d.linear_distance < stop)].ld.mean()\n",
    "    \n",
    "plt.scatter(\n",
    "    x='linear_distance',\n",
    "    y='ld',\n",
    "    data=d,\n",
    "    s=1,\n",
    "    alpha=0.05,\n",
    "    color='black',\n",
    "    label='__nolegend__',\n",
    ")\n",
    "plt.scatter([], [], s=10, color='black', label='Locus Pair')\n",
    "plt.plot(pd.Series(bins), color='red', label='Mean LD (25 bp Bin)')\n",
    "plt.axhline(0, lw=1, color='red', linestyle='--')\n",
    "plt.ylabel(r\"LD\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.legend(bbox_to_anchor=(0.85, 1.15), ncol=2)\n",
    "\n",
    "print(sp.stats.spearmanr(d['linear_distance'], d['ld']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100022 (F. prausnitzii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info(\"Loading input data.\")\n",
    "data = load_input_data(['data/core.sp-100022.gtpro-pileup.nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_ss, data_fit, history = sf.workflow.filter_subsample_and_fit(\n",
    "    data,\n",
    "    incid_thresh=0.1,\n",
    "    cvrg_thresh=0.5,\n",
    "    npos=500,\n",
    "    preclust=False,\n",
    "#     preclust_kwargs=dict(\n",
    "#         thresh=0.1,\n",
    "#         additional_strains_factor=0.,\n",
    "#         progress=True,\n",
    "#     ),\n",
    "    fit_kwargs=dict(\n",
    "        s=1000,\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.01,\n",
    "        rho_hyper=0.5,\n",
    "        mu_hyper_mean=5,\n",
    "        mu_hyper_scale=5.,\n",
    "        m_hyper_r=10.,\n",
    "        delta_hyper_temp=0.1,\n",
    "        delta_hyper_p=0.9,\n",
    "        alpha_hyper_hyper_mean=100.,\n",
    "        alpha_hyper_hyper_scale=10.,\n",
    "        alpha_hyper_scale=0.5,\n",
    "        epsilon_hyper_alpha=1.5,\n",
    "        epsilon_hyper_beta=1.5 / 0.01,\n",
    "        device='cuda',\n",
    "        lag=100,\n",
    "        lr=1e-1,\n",
    "        progress=True\n",
    "    ),\n",
    "    postclust_kwargs=dict(\n",
    "        thresh=0.25,\n",
    "        progress=True,\n",
    "    ),\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(mrg_ss['alpha']), bins=100)\n",
    "#plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(mrg_ss['epsilon']), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_strains = (mrg_ss['pi'] > 0.75).sum(0).argsort()[-50:]\n",
    "top_samples = ((mrg_ss['pi'][:,top_strains] > 0.25).sum(1)).argsort()[-100:]\n",
    "\n",
    "sf.plot.plot_community(\n",
    "    mrg_ss['pi'][top_samples][:, top_strains],\n",
    "    yticklabels=1,\n",
    "    row_colors=mpl.cm.viridis(np.log10(mrg_ss['alpha'][top_samples])),\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    "    norm=mpl.colors.PowerNorm(1/3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sf.plot.plot_genotype(\n",
    "    mrg_ss['gamma'][top_strains],\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sf.plot.plot_missing(\n",
    "    mrg_ss['delta'][top_strains],\n",
    "    col_colors=mpl.cm.viridis(sf.evaluation.mean_masked_genotype_entropy(mrg_ss['gamma'], mrg_ss['delta'])[top_strains]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_estimate = sf.genotype.counts_to_p_estimate(\n",
    "    data_fit.sel(allele='alt'), data_fit.sum('allele')\n",
    ")\n",
    "\n",
    "sf.plot.plot_genotype(p_estimate.values[top_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition = pd.DataFrame(mrg_ss['pi'], index=data_fit.library_id)\n",
    "composition = composition.reindex(meta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = composition[meta['Study'].isin(['VatanenT_2016'])]\n",
    "strains = idxwhere((composition[meta['Study'].isin(['VatanenT_2016'])] > 0.5).sum() > 1)\n",
    "\n",
    "sf.plot.plot_community(\n",
    "    d.loc[:, strains],\n",
    "    yticklabels=1,\n",
    "    norm=mpl.colors.PowerNorm(1/3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This is a giant contingency table,\n",
    "# and the p-value on a chisq test shows clearly that strains clump\n",
    "# into countries.\n",
    "\n",
    "contingency = (\n",
    "    composition\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency = (\n",
    "    composition\n",
    "    .set_index(composition.sample(frac=1.0).index)\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pairs = pd.read_table('raw/shi2019s14.tsv').set_index(['Sample Run 1', 'Sample Run 2'])\n",
    "\n",
    "bc_dist = {}\n",
    "cos_dist = {}\n",
    "\n",
    "for libraryA, libraryB in tqdm(sample_pairs.index):\n",
    "    if (libraryA not in composition.index) or (libraryB not in composition.index):\n",
    "        continue\n",
    "    bc_dist[(libraryA, libraryB)] = braycurtis(composition.loc[libraryA], composition.loc[libraryB])\n",
    "    cos_dist[(libraryA, libraryB)] = cosine(p_estimate.loc[libraryA], p_estimate.loc[libraryB])\n",
    "\n",
    "sample_pairs = sample_pairs.assign(bc=pd.Series(bc_dist), cos=pd.Series(cos_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot('Group Type', 'bc', data=sample_pairs, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot('Group Type', 'cos', data=sample_pairs, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('cos', 'bc', data=sample_pairs, kind='hex', norm=mpl.colors.PowerNorm(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rarefaction = []\n",
    "strain_counts = defaultdict(lambda: 0)\n",
    "for strain_id in composition.idxmax(1).sample(frac=1.0).values:\n",
    "    strain_counts[strain_id] += 1\n",
    "    rarefaction.append(len(strain_counts))\n",
    "rarefaction = np.array(rarefaction)\n",
    "\n",
    "plt.plot(rarefaction)\n",
    "plt.plot([0, 400], [0, 400], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_incidence = (composition > 1e-1).sum()\n",
    "\n",
    "observed_total = len(strain_incidence)\n",
    "observed_singletons = (strain_incidence == 1).sum()\n",
    "observed_doubletons = (strain_incidence == 2).sum()\n",
    "\n",
    "chao2 = observed_total + ((observed_singletons**2) / (2 * observed_doubletons))\n",
    "print(chao2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est, data_filt, position_ss = sf.workflow.filter_subsample_fit_and_refit_genotypes(\n",
    "    data,\n",
    "    incid_thresh=0.1,\n",
    "    cvrg_thresh=0.25,\n",
    "    npos=500,\n",
    "    preclust=False,\n",
    "#     preclust_kwargs=dict(\n",
    "#         thresh=0.1,\n",
    "#         additional_strains_factor=0.,\n",
    "#         progress=True,\n",
    "#     ),\n",
    "    fit_kwargs=dict(\n",
    "        s=1000,\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=0.01,\n",
    "        rho_hyper=0.5,\n",
    "        mu_hyper_mean=5,\n",
    "        mu_hyper_scale=5.,\n",
    "        m_hyper_r=10.,\n",
    "        delta_hyper_temp=0.1,\n",
    "        delta_hyper_p=0.9,\n",
    "        alpha_hyper_hyper_mean=100.,\n",
    "        alpha_hyper_hyper_scale=10.,\n",
    "        alpha_hyper_scale=0.5,\n",
    "#         alpha_hyper_hyper_mean=10000.,\n",
    "#         alpha_hyper_hyper_scale=0.001,\n",
    "#         alpha_hyper_scale=0.001,\n",
    "        epsilon_hyper_alpha=1.5,\n",
    "        epsilon_hyper_beta=1.5 / 0.01,\n",
    "        device='cuda',\n",
    "        lag=100,\n",
    "        lr=1e-1,\n",
    "        progress=True\n",
    "    ),\n",
    "    postclust_kwargs=dict(\n",
    "        thresh=0.25,\n",
    "        progress=True,\n",
    "    ),\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "pickle.dump(est, open('data/core.sp-100022.gtpro-pileup.sf-est.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est['gamma'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_genotype(est['gamma'], row_cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est['gamma'].mean(0), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((est['pi'] @ est['gamma']).mean(0), bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_meta = all_species_position_meta_[lambda x: x.species_id == 100022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_meta.loc[data_filt.position]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}