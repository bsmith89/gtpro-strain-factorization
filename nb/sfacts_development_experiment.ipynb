{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sfacts.logging_util import *\n",
    "from sfacts.pyro_util import *\n",
    "from sfacts.model import *\n",
    "from sfacts.genotype import *\n",
    "from sfacts.plot import *\n",
    "from sfacts.estimation import *\n",
    "from sfacts.evaluation import *\n",
    "from sfacts.workflow import *\n",
    "from sfacts.data import *\n",
    "from sfacts.pandas_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from torch.jit import TracerWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\",\n",
    "    category=torch.jit.TracerWarning,\n",
    "#     module=\"trace_elbo\",  # FIXME: What is the correct regex for module?\n",
    "#     lineno=5,\n",
    ")\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on sfacts/data.py\n",
    "np.random.seed(1)\n",
    "\n",
    "mgen_all = (\n",
    "    sf.data.Metagenotypes.load('data/core.sp-100022.gtpro-pileup.nc', validate=False)\n",
    ")\n",
    "\n",
    "mgen_filt = (\n",
    "    mgen_all\n",
    "    .select_variable_positions(thresh=0.02)\n",
    "    .select_samples_with_coverage(0.1)\n",
    ")\n",
    "print(mgen_filt.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.plot.plot_metagenotype(\n",
    "#     obs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 500"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "approx = sf.estimation.nmf_approximation(obs, s, random_state=1, alpha=0., solver='cd', init='random', tol=1e-4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_genotype(approx, matrix_func=lambda x: x.genotypes.fuzzed(1e-0).to_pandas())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_community(approx, matrix_func=lambda x: x.communities.fuzzed(1e-2).to_pandas().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = (\n",
    "    sf.workflow.fit_subsampled_metagenotype_collapse_strains_then_iteratively_refit_full_genotypes(\n",
    "        sf.model_zoo.full_metagenotype_dirichlet_rho_model_structure,\n",
    "        mgen_filt.random_sample(500, 'position'),\n",
    "        nstrain=s,\n",
    "        nposition=500,\n",
    "        thresh=0.01,\n",
    "        hyperparameters=dict(\n",
    "            gamma_hyper=0.1,\n",
    "            delta_hyper_r=0.8,\n",
    "            delta_hyper_temp=0.1,\n",
    "            rho_hyper=1.0,\n",
    "            pi_hyper=1.0,\n",
    "            epsilon_hyper_mode=0.01,\n",
    "            epsilon_hyper_spread=1.5,\n",
    "            alpha_hyper_hyper_mean=1000.0,\n",
    "            alpha_hyper_hyper_scale=0.5,\n",
    "            alpha_hyper_scale=1.0,\n",
    "        ),\n",
    "        stage2_hyperparameters=dict(gamma_hyper=1.0),\n",
    "        device=device,\n",
    "        quiet=False,\n",
    "        estimation_kwargs=dict(\n",
    "            lagA=10,\n",
    "            lagB=100,\n",
    "            opt=pyro.optim.Adamax({\"lr\": 1e-0}, {\"clip_norm\": 100}),\n",
    "            seed=2,\n",
    "            jit=True,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# sf.plot.plot_loss_history(history0)\n",
    "# sf.plot.plot_loss_history(history1)\n",
    "# sf.plot.plot_loss_history(history2)\n",
    "# sf.plot.plot_loss_history(history3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys, gc\n",
    "# del sys.last_value\n",
    "# del sys.last_type\n",
    "del sys.last_traceback\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_community(\n",
    "    est,\n",
    "    col_colors_func=lambda w: xr.Dataset(dict(\n",
    "        mgen_entropy=w.metagenotypes.entropy(),\n",
    "        expect_entropy=w.data['p'].pipe(sf.math.binary_entropy).mean(\"position\"),\n",
    "        mean_cvrg=w.metagenotypes.sum(\"allele\").mean(\"position\").pipe(np.sqrt),\n",
    "        m_hyper_r=w.data['m_hyper_r'],\n",
    "        alpha=w.data['alpha'].pipe(np.sqrt),\n",
    "        flag=(w.data.alpha < 10) & (w.metagenotypes.sum(\"allele\").mean(\"position\") > 20),\n",
    "    )),\n",
    "    row_colors_func=lambda w: xr.Dataset(dict(\n",
    "        entropy=w.genotypes.entropy(),\n",
    "        mean_cvrg=(w.communities.data * w.metagenotypes.sum(\"allele\").mean(\"position\")).sum(\"sample\").pipe(np.sqrt),\n",
    "    )),\n",
    "    scalex=0.1, scaley=0.1,row_linkage_func=None,col_linkage_func=None,\n",
    "#     col_linkage_func=lambda w: w.genotypes.cosine_linkage(),\n",
    "#     row_linkage_func=lambda w: sf.data.latent_metagenotypes_linkage(w),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_genotype(\n",
    "    est1,\n",
    "    row_colors_func=lambda w: xr.Dataset(dict(\n",
    "        entropy=w.genotypes.entropy(),\n",
    "        mean_cvrg=(w.communities.data * w.metagenotypes.sum(\"allele\").mean(\"position\")).sum(\"sample\").pipe(np.log),\n",
    "    )),\n",
    "    row_linkage_func=None,\n",
    "    col_linkage_func=None,\n",
    "#     row_linkage_func=lambda w: w.genotypes.cosine_linkage(),\n",
    "#     col_linkage_func=lambda w: w.metagenotypes.linkage(dim='position'),\n",
    "    isel=dict(position=slice(0, 500)),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_missing(\n",
    "    est3,\n",
    "    row_colors_func=lambda w: xr.Dataset(dict(\n",
    "        entropy=w.genotypes.entropy(),\n",
    "        mean_cvrg=(w.communities.data * w.metagenotypes.sum(\"allele\").mean(\"position\")).sum(\"sample\").pipe(np.log),\n",
    "    )),\n",
    "    row_linkage_func=lambda w: w.genotypes.cosine_linkage(),\n",
    "    col_linkage_func=lambda w: w.metagenotypes.linkage(dim='position'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    est3,\n",
    "#     row_colors_func=lambda w: xr.Dataset(dict(\n",
    "#         entropy=w.genotypes.entropy(),\n",
    "#         mean_cvrg=(w.communities.data * w.metagenotypes.sum(\"allele\").mean(\"position\")).sum(\"sample\").pipe(np.log),\n",
    "#     )),\n",
    "#     row_linkage_func=lambda w: w.genotypes.cosine_linkage(),\n",
    "    row_linkage_func=lambda w: w.metagenotypes.linkage(dim='position'),\n",
    "    col_linkage_func=lambda w: sf.data.latent_metagenotypes_linkage(w),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est3.data.communities.max(\"sample\").pipe(np.log10), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est3.data.alpha.pipe(np.log10), bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est3.data.epsilon.pipe(np.log10), bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est3.data.m_hyper_r.pipe(np.log10), bins=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(est3.data.m_hyper_r, est3.data.alpha, c=est3.data.mu, alpha=0.5, s=5)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = est\n",
    "\n",
    "sf.plot.plot_genotype(sf.data.World.concat({\n",
    "    'est0': est0,\n",
    "    'est1': est,\n",
    "}, dim='strain'),\n",
    "    row_colors_func=lambda w: xr.Dataset(dict(\n",
    "        entropy=w.genotypes.entropy(),\n",
    "        missingness=1 - w.missingness.mean('position'),\n",
    "        mean_cvrg=(w.communities.data * w.metagenotypes.sum(\"allele\").mean(\"position\")).sum(\"sample\").pipe(np.log),\n",
    "    )),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_missing(est)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_missing(est0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_list = ['DS0097_001', 'DS0097_014', 'DS0097_027', 'DS0097_005', 'SS01057']\n",
    "sample_list = sf.pandas_util.idxwhere(est3.sample.str.startswith('DS0097').to_pandas())[:5]\n",
    "# sample_list = [\n",
    "#     'DS0097_032',\n",
    "#     'DS0044_002',\n",
    "#     'DS0044_005',\n",
    "#     'DS0044_006',\n",
    "#     'DS0044_007',\n",
    "#     'DS0044_008',\n",
    "#     'DS0044_009',\n",
    "#     'DS0044_010',\n",
    "#     'SS01068',\n",
    "#     'SS01147',\n",
    "#     'SS01057',\n",
    "#     'SS01134',\n",
    "#     'SS01163',\n",
    "#     'SS01171',\n",
    "#     'SS01172',\n",
    "#     'SS01026',\n",
    "#     'SS01022',\n",
    "# ]\n",
    "\n",
    "sf.plot.plot_metagenotype_frequency_spectrum(est3, sample_list=sample_list, show_dominant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = est2\n",
    "\n",
    "model_sim = (\n",
    "    sf.model.ParameterizedModel(\n",
    "        sf.model_zoo.full_metagenotype_model_structure,\n",
    "        coords=dict(\n",
    "            sample=d.sample.values,\n",
    "            position=d.position.values,\n",
    "            allele=d.allele.values,\n",
    "            strain=d.strain.values,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "resim = model_sim.condition(\n",
    "    pi=d.communities.values,\n",
    "#     gamma=d.genotypes.discretized().fuzzed().values,\n",
    "    gamma=d.genotypes.values,\n",
    "    m=d.data['m'].values,\n",
    "    epsilon=d.data['epsilon'].values,\n",
    "    alpha=d.data['alpha'].values,\n",
    "#     epsilon=np.ones_like(d.data['epsilon'].values) * 1e-5,\n",
    "#     alpha=np.ones_like(d.data['alpha'].values) * 1e5,\n",
    ").simulate_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_list = ['SS01038', 'SS01054','SS01052', 'SS01063', 'DS0485_002', 'DS0097_001', 'DS0097_027']\n",
    "sample_list = sf.pandas_util.idxwhere(est2.sample.str.startswith('DS0097').to_pandas())\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(11, 9), sharey=True)\n",
    "\n",
    "for sample, ax in zip(sample_list, axs.flatten()):\n",
    "    sf.plot.plot_metagenotype_frequency_spectrum_comparison(dict(obs=obs, resim=resim), sample=sample, ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1, 1e4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = est3\n",
    "_data = xr.Dataset(dict(\n",
    "        mgen_entropy=w.metagenotypes.entropy(),\n",
    "        expect_entropy=w.data['p'].pipe(sf.math.binary_entropy).mean(\"position\"),\n",
    "        mean_cvrg=w.metagenotypes.sum(\"allele\").mean(\"position\"),\n",
    "        alpha=w.data['alpha'].pipe(np.log),\n",
    "    )).to_dataframe()\n",
    "\n",
    "plt.scatter(x='expect_entropy', y='mgen_entropy', data=_data, s='mean_cvrg', c='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data Viz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(est.genotypes.to_pandas().T, vmin=0, vmax=1, center=0.5, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_sample_coverage = est.metagenotypes.sum('allele').mean('position')\n",
    "plt.hist(inferred_sample_coverage.pipe(np.log10), bins=50)\n",
    "\n",
    "plt.xlabel('log10(mean species/sample coverage)')\n",
    "plt.ylabel('count')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inferred_strain_coverage = (est.metagenotypes.sum('allele').mean('position') * est.communities.data).sum('sample')\n",
    "plt.hist(total_inferred_strain_coverage.pipe(np.log10), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_single_sample_inferred_strain_coverage = (est.metagenotypes.sum('allele').mean('position') * est.communities.data).max('sample')\n",
    "plt.hist(max_single_sample_inferred_strain_coverage.pipe(np.log10), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(max_single_sample_inferred_strain_coverage, total_inferred_strain_coverage, s=5)\n",
    "plt.plot([0, 1e3], [0, 1e3])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(est.missingness.to_pandas().T, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(est.communities.to_pandas(), vmin=0, vmax=1, norm=mpl.colors.PowerNorm(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est.communities.max('sample'), bins=np.linspace(0, 1, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est.genotypes.values.flatten(), bins=np.linspace(0, 1, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est.missingness.values.flatten(), bins=np.linspace(0, 1, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biogeography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta = pd.read_table('raw/shi2019s13.tsv').set_index('NCBI Accession Number')\n",
    "sample_meta.groupby(['Study', 'Continent']).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct composition matrix for samples with biogeography data\n",
    "\n",
    "composition = est.communities.to_pandas()\n",
    "meta = sample_meta.reindex(composition.index).dropna(subset=['Sample ID'])\n",
    "composition_bg = composition.reindex(meta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfacts.pandas_util import idxwhere\n",
    "\n",
    "d = composition_bg[meta['Study'].isin(['VatanenT_2016'])]\n",
    "strains = idxwhere((composition_bg[meta['Study'].isin(['VatanenT_2016'])] > 0.5).sum() > 1)\n",
    "\n",
    "# sf.plot.plot_community(\n",
    "#     d.loc[:, strains],\n",
    "#     yticklabels=1,\n",
    "#     norm=mpl.colors.PowerNorm(1/3),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This is a giant contingency table,\n",
    "# and the p-value on a chisq test shows clearly that strains clump\n",
    "# into countries.\n",
    "\n",
    "contingency = (\n",
    "    composition_bg\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency = (\n",
    "    composition_bg\n",
    "    .set_index(composition_bg.sample(frac=1.0).index)\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same analysis, but carefully selecting studies that I don't believe have\n",
    "# multiple metagenomes from same/related individuals.\n",
    "\n",
    "contingency2 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency2 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .set_index(composition_bg[meta['Study'].isin(select_studies)].sample(frac=1.0).index)\n",
    "    .groupby(meta['Country'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency2)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same analysis, but carefully selecting studies that I don't believe have\n",
    "# multiple metagenomes from same/related individuals.\n",
    "# And clustering by study rather than country.\n",
    "\n",
    "contingency3 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .groupby(meta['Study'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "null_contingency3 = (\n",
    "    composition_bg\n",
    "    [meta['Study'].isin(select_studies)]\n",
    "    .set_index(composition_bg[meta['Study'].isin(select_studies)].sample(frac=1.0).index)\n",
    "    .groupby(meta['Study'])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "assert sp.stats.chi2_contingency(null_contingency3)[1] > 0.01\n",
    "\n",
    "print(sp.stats.chi2_contingency(contingency3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['Study'].isin(select_studies)].groupby('Study').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta[meta['Study'].isin(select_studies)].groupby('Country').apply(len)\n",
    "\n",
    "top_20_strains = contingency2.apply(lambda x: x / x.sum(), axis=1).mean().sort_values(ascending=False).head(20).index\n",
    "\n",
    "ax = (\n",
    "    contingency2\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .loc[['CHN', 'MDG', 'AUT', 'DEU', 'SWE'], top_20_strains]\n",
    "    .plot\n",
    "    .bar(stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)))\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top 20 Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.groupby(['Study', 'Country']).apply(len).unstack(fill_value=0).loc[select_studies].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta[meta['Study'].isin(select_studies)].groupby('Country').apply(len)\n",
    "\n",
    "top_20_strains = contingency3.apply(lambda x: x / x.sum(), axis=1).mean().sort_values(ascending=False).head(20).index\n",
    "\n",
    "ax = (\n",
    "    contingency3\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    "    .loc[:, top_20_strains]\n",
    "    .plot\n",
    "    .bar(stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)))\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top 20 Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_individuals = meta.groupby([meta['Continent'], meta['Country'], meta['Study']]).apply(len)\n",
    "\n",
    "d = (\n",
    "    composition_bg\n",
    "    .groupby([meta['Continent'], meta['Country'], meta['Study']])\n",
    "    .apply(lambda d: d.idxmax(1).value_counts())\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    ")\n",
    "top_strains = d.mean().sort_values(ascending=False).head(15).index\n",
    "\n",
    "d = d.loc[:, top_strains].assign(other=1 - d.loc[:, top_strains].sum(1)).drop(idxwhere(count_individuals < 10))\n",
    "\n",
    "ax = (\n",
    "    d\n",
    "    .plot\n",
    "    .bar(\n",
    "        stacked=True, color=mpl.cm.tab20(np.linspace(0, 1, num=20)),\n",
    "        figsize=(10, 5)\n",
    "    )\n",
    ")\n",
    "#ax.legend_.set_visible(False)\n",
    "ax.legend(bbox_to_anchor=(1, 1), title='Top Strains')\n",
    "\n",
    "ax.set_ylabel('Fraction samples where dominant')\n",
    "# rotate_xticklabels()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "82px",
    "width": "168px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}