{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from torch.jit import TracerWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\",\n",
    "    category=TracerWarning,\n",
    "#     module=\"trace_elbo\",  # FIXME: What is the correct regex for module?\n",
    "#     lineno=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0: Average and variation in fitting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for seed_fit in range(10):\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=200,\n",
    "            n_sim=1000,\n",
    "            g_sim=1000,\n",
    "            n_fit=1000,\n",
    "            g_fit=1000,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cuda'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=200,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.01,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cuda',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed_fit,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((seed_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(seed_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results0 = pd.DataFrame(results, columns=['seed_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results0.set_index(['seed_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Sensitivity to strain misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for s_fit in [100, 175, 200, 225, 300, 500]:\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=200,\n",
    "            n_sim=1000,\n",
    "            g_sim=1000,\n",
    "            n_fit=1000,\n",
    "            g_fit=1000,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cuda'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=s_fit,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.01,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cuda',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((s_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(s_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results1 = pd.DataFrame(results, columns=['s_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results1.set_index(['s_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Benefits of increasing sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n_fit in [500, 1500, 2500, 4000]:\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=200,\n",
    "            n_sim=4000,\n",
    "            g_sim=1000,\n",
    "            n_fit=n_fit,\n",
    "            g_fit=1000,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cuda'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=200,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.01,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cuda',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((n_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(n_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results2 = pd.DataFrame(results, columns=['n_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results2.set_index(['n_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Benefits of increasing genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for g_fit in [100, 250, 500, 1000, 2000]:\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=200,\n",
    "            n_sim=1000,\n",
    "            g_sim=2000,\n",
    "            n_fit=1000,\n",
    "            g_fit=g_fit,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=1.,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cuda'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=200,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.01,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cuda',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((g_fit, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(g_fit, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results3 = pd.DataFrame(results, columns=['g_fit', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results3.set_index(['g_fit', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Benefits of increasing depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for mu_hyper_mean_sim in [0.5, 1.0, 2.0, 5.0, 15.0]:\n",
    "    for seed in [0, 1, 3, 4, 5]:\n",
    "        generr, comperr, scounter, entropy, runtime, sim, fit = sf.workflow.simulate_fit_and_evaluate(\n",
    "            s_sim=200,\n",
    "            n_sim=1000,\n",
    "            g_sim=1000,\n",
    "            n_fit=1000,\n",
    "            g_fit=1000,\n",
    "            sim_kwargs=dict(\n",
    "                data=dict(\n",
    "                    alpha_hyper_mean=100.\n",
    "                ),\n",
    "                gamma_hyper=0.01,\n",
    "                delta_hyper_temp=0.01,\n",
    "                delta_hyper_p=0.7,\n",
    "                pi_hyper=0.5,\n",
    "                rho_hyper=2.,\n",
    "                mu_hyper_mean=mu_hyper_mean_sim,\n",
    "                mu_hyper_scale=0.5,\n",
    "                m_hyper_r=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5/0.01,\n",
    "                device='cuda'\n",
    "            ),\n",
    "            preclust=False,\n",
    "            fit_kwargs=dict(\n",
    "                s=200,\n",
    "                gamma_hyper=0.01,\n",
    "                pi_hyper=0.01,\n",
    "                rho_hyper=0.5,\n",
    "                mu_hyper_mean=5,\n",
    "                mu_hyper_scale=5.,\n",
    "                m_hyper_r=10.,\n",
    "                delta_hyper_temp=0.1,\n",
    "                delta_hyper_p=0.9,\n",
    "                alpha_hyper_hyper_mean=100.,\n",
    "                alpha_hyper_hyper_scale=10.,\n",
    "                alpha_hyper_scale=0.5,\n",
    "                epsilon_hyper_alpha=1.5,\n",
    "                epsilon_hyper_beta=1.5 / 0.01,\n",
    "                device='cuda',\n",
    "                lag=10,\n",
    "                lr=1e-1,\n",
    "                progress=True\n",
    "            ),\n",
    "            postclust_kwargs=dict(\n",
    "                thresh=0.1,\n",
    "            ),\n",
    "            seed_sim=seed,\n",
    "            seed_fit=seed,\n",
    "            quiet=True,\n",
    "        )\n",
    "        results.append((mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime))\n",
    "        print(mu_hyper_mean_sim, seed, generr, comperr, scounter, entropy, runtime, sep='\\t')\n",
    "         \n",
    "results4 = pd.DataFrame(results, columns=['mu_hyper_mean_sim', 'seed', 'generr', 'comperr', 'scounterr', 'entropy', 'runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "for stat, ax in zip(['generr', 'comperr', 'scounterr', 'entropy', 'runtime'], axs.flatten()):\n",
    "    results4.set_index(['mu_hyper_mean_sim', 'seed'])[stat].unstack().plot(ax=ax)\n",
    "    ax.set_title(stat)\n",
    "    ax.legend_.set_visible(False)\n",
    "    if stat == 'generr':\n",
    "        ax.set_yscale('log')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Big matrix plot.\n",
    "\n",
    "all_results = [\n",
    "    (results1, 's_fit', 'linear', 1),\n",
    "    (results2, 'g_fit', 'log', 2),\n",
    "]\n",
    "\n",
    "all_stats = [\n",
    "    ('generr', 'log'),\n",
    "    ('comperr', 'log'),\n",
    "    ('scounterr', 'symlog'),\n",
    "    ('entropy', 'linear'),\n",
    "    ('runtime', 'log')\n",
    "]\n",
    "\n",
    "nres = len(all_results)\n",
    "nstat = len(all_stats)\n",
    "\n",
    "fig, axs = plt.subplots(nstat, nres, figsize=(2 * nres, 2 * nstat), sharex='col', sharey='row')\n",
    "axs = axs.reshape((nstat, nres))\n",
    "\n",
    "for (stat, scale_y), row in zip(all_stats, axs):\n",
    "    for (results, indexer, scale_x, title), ax in zip(all_results, row):\n",
    "        results.set_index([indexer, 'seed'])[stat].unstack().plot(ax=ax)\n",
    "        ax.set_ylabel(stat)\n",
    "        ax.set_xlabel(indexer)\n",
    "        ax.legend_.set_visible(False)\n",
    "        ax.set_xscale(scale_x)\n",
    "        ax.set_yscale(scale_y)\n",
    "        ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}