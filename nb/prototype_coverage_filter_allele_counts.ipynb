{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.util import info, idxwhere\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import logit\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = 100022\n",
    "group = 'core'\n",
    "inpath = f'data/{group}/{species_id}/gtpro.nc'\n",
    "\n",
    "data = xr.open_dataarray(inpath).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg = data.sum(dim=['allele', 'read'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(data.isel(position=1), bins=np.linspace(0, 1000, num=50))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.concatenate([np.arange(100), np.arange(int(np.sqrt(100)), int(np.sqrt(2000)))**2])\n",
    "\n",
    "cvrg_hist = (\n",
    "    cvrg\n",
    "    .to_pandas()\n",
    "    .apply(lambda x: np.histogram(x, bins=bins, density=True)[0])\n",
    "    .set_index(bins[1:])\n",
    "    .rename_axis(index='bin_high')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(cvrg_hist.loc[:, cvrg_hist.iloc[0].sort_values().index], norm=mpl.colors.SymLogNorm(linthresh=1e-7), xticklabels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcvrg = cvrg / cvrg.mean('position')\n",
    "\n",
    "bins = np.logspace(0, 2.5, num=100) - 1\n",
    "rcvrg_hist = (\n",
    "    rcvrg\n",
    "    .to_pandas()\n",
    "    .apply(lambda x: np.histogram(x, bins=bins, density=True)[0])\n",
    "    .set_index(bins[1:])\n",
    "    .rename_axis(index='bin_high')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(rcvrg_hist.loc[:, rcvrg_hist.iloc[0].sort_values().index], norm=mpl.colors.SymLogNorm(linthresh=1e-5), xticklabels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = 100022\n",
    "pathfmt = 'data/core/{species_id}/gtpro.read_r{r}.tsv.bz2'\n",
    "\n",
    "r1 = (\n",
    "    pd.read_table(\n",
    "        pathfmt.format(species_id=species_id, r=1),\n",
    "        names=[\n",
    "            \"library_id\",\n",
    "            \"species_id\",\n",
    "            \"position\",\n",
    "            \"_3\",\n",
    "            \"_4\",\n",
    "            \"_5\",\n",
    "            \"_6\",\n",
    "            \"ref\",\n",
    "            \"alt\",\n",
    "        ],\n",
    "        index_col=[\"library_id\", \"species_id\", \"position\"],\n",
    "    )[[\"ref\", \"alt\"]]\n",
    "    .rename_axis(columns=\"allele\")\n",
    "    .stack()\n",
    "    .astype(int)\n",
    "    .squeeze()\n",
    ")\n",
    "\n",
    "r2 = (\n",
    "    pd.read_table(\n",
    "        pathfmt.format(species_id=species_id, r=2),\n",
    "        names=[\n",
    "            \"library_id\",\n",
    "            \"species_id\",\n",
    "            \"position\",\n",
    "            \"_3\",\n",
    "            \"_4\",\n",
    "            \"_5\",\n",
    "            \"_6\",\n",
    "            \"ref\",\n",
    "            \"alt\",\n",
    "        ],\n",
    "        index_col=[\"library_id\", \"species_id\", \"position\"],\n",
    "    )[[\"ref\", \"alt\"]]\n",
    "    .rename_axis(columns=\"allele\")\n",
    "    .stack()\n",
    "    .astype(int)\n",
    "    .squeeze()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    pd.concat([\n",
    "        r1.to_frame('r1').rename_axis(columns='read').stack(),\n",
    "        r2.to_frame('r2').rename_axis(columns='read').stack()\n",
    "    ])\n",
    "    .to_xarray()\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataseries = \n",
    "sdata = data.to_series()[lambda x: ~(x == 0)].astype(int).to_frame('tally')\n",
    "sdata.to_parquet('test.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.to_parquet('test.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Stack them together into one dataframe,\n",
    "# rename the columns to 'read', and then unstack.\n",
    "\n",
    "data = pd.DataFrame(dict(r1=r1, r2=r2)).rename_axis(columns='read').unstack().to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "info(data.sizes)\n",
    "\n",
    "cvrg = data.sum('allele')\n",
    "\n",
    "# alt_frac = data.sel(allele='alt') / cvrg\n",
    "# has_alt_pos_frac = (alt_frac > 0).sum('snp_idx') / (alt_frac.notnull()).sum('snp_idx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mean_cvrg = cvrg.mean('library_id')\n",
    "plt.hist(pos_mean_cvrg.values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_incid = (cvrg > 0).mean('library_id')\n",
    "plt.hist(pos_incid.values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For each position, see how the probability of hitting that\n",
    "# position increases with increasing library coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log2_cvrg_ratio = np.log2((cvrg + 1) / (cvrg + 1).reduce(lambda x, axis: sp.stats.trim_mean(x, 0.05, axis), 'snp_idx'))\n",
    "pos_log2_cvrg_ratio_mean = log2_cvrg_ratio.mean('library_id')\n",
    "pos_log2_cvrg_ratio_mean_anomaly = np.abs(pos_log2_cvrg_ratio_mean) > 0.5\n",
    "\n",
    "plt.hist(pos_log2_cvrg_ratio_mean.values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_log2_cvrg_ratio_std = log2_cvrg_ratio.std('library_id')\n",
    "pos_log2_cvrg_ratio_std_anomaly = pos_log2_cvrg_ratio_std > 1.5\n",
    "\n",
    "plt.hist(pos_log2_cvrg_ratio_std.values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_log2_cvrg_ratio_std = log2_cvrg_ratio.std('snp_idx')\n",
    "library_log2_cvrg_ratio_std_anomaly = library_log2_cvrg_ratio_std > 1.5\n",
    "\n",
    "plt.hist(library_log2_cvrg_ratio_std.values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_log2_cvrg_ratio_std_anomaly.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how the number of positions \"seen\" per library increases with coverage.\n",
    "# TODO: Drop libraries where this is way out-of-whack, as these suggest\n",
    "# problems (e.g. some genome not in the database with homology to just a few positions)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.scatter(cvrg.mean('snp_idx'), (cvrg > 0).mean('snp_idx'), s=1, alpha=0.5)\n",
    "plt.xscale('log')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_log2_cvrg_ratio_mean_anomaly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_log2_cvrg_ratio_std_anomaly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pos_log2_cvrg_ratio_mean_anomaly | pos_log2_cvrg_ratio_std_anomaly).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_allele_frac = (data / cvrg).mean('library_id')\n",
    "\n",
    "plt.hist(mean_allele_frac.sel(allele='alt').values, bins=100)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cvrg.sum('snp_idx').values, bins=100)\n",
    "plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Decide if I want to down-sample high-coverage libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}