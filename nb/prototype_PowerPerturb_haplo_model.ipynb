{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import pyro.infer\n",
    "from lib.util import info\n",
    "\n",
    "import pyro.primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def power_perturb_rvs(alpha):\n",
    "    x = scipy.stats.dirichlet(np.ones_like(alpha)).rvs()\n",
    "    x_pow = np.power(x, 1 / alpha)\n",
    "    x_pow_norm = x_pow / x_pow.sum(-1)\n",
    "    return x_pow_norm\n",
    "\n",
    "frac = np.array([0.95, 0.05])\n",
    "conc = 1e-2\n",
    "x = np.concatenate([power_perturb_rvs(frac * conc) for _ in range(10000)])\n",
    "x.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_perturb_model(alpha, name='x'):\n",
    "    x = pyro.sample(name, dist.Dirichlet(torch.ones_like(alpha)))\n",
    "    log_x_pow = torch.log(x) / alpha\n",
    "    log_x_pow_norm = log_x_pow - torch.logsumexp(log_x_pow, -1, keepdim=True)\n",
    "    return torch.exp(log_x_pow_norm)\n",
    "\n",
    "x = power_perturb_model(torch.ones((100, 200))*1e-1)\n",
    "\n",
    "sns.heatmap(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    s,\n",
    "    m,\n",
    "    y=None,\n",
    "    gamma0=1.0,\n",
    "    pi0=1.0,\n",
    "    rho0=1.0,\n",
    "    epsilon0=0.01,\n",
    "    alpha0=100.0,\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "\n",
    "    # Cast inputs and set device\n",
    "    m, gamma0, pi0, rho0, epsilon0, alpha0 = [\n",
    "        torch.tensor(v, dtype=dtype, device=device)\n",
    "        for v in [m, gamma0, pi0, rho0, epsilon0, alpha0]\n",
    "    ]\n",
    "    if y is not None:\n",
    "        y = torch.tensor(y)\n",
    "\n",
    "    n, g = m.shape\n",
    "    \n",
    "    gamma_hyper = pyro.sample(\"gamma_hyper\", dist.Gamma(gamma0, 1.0))\n",
    "\n",
    "    with pyro.plate(\"position\", g, dim=-1):\n",
    "        with pyro.plate(\"strain\", s, dim=-2):\n",
    "            gamma = pyro.sample(\"gamma\", dist.Beta(gamma_hyper, gamma_hyper))\n",
    "    # gamma.shape == (s, g)\n",
    "\n",
    "    rho_hyper = pyro.sample(\"rho_hyper\", dist.Gamma(rho0, 1.0))\n",
    "    rho_raw = pyro.sample(\n",
    "        \"rho_raw\",\n",
    "        dist.Dirichlet(torch.ones(s, dtype=dtype, device=device)),\n",
    "    )\n",
    "    log_rho_raw_pow = torch.log(rho_raw) / (rho_hyper)\n",
    "    log_rho = log_rho_raw_pow - torch.logsumexp(log_rho_raw_pow, -1, keepdim=True)\n",
    "    rho = pyro.deterministic('rho', torch.exp(log_rho))\n",
    "    \n",
    "\n",
    "    epsilon_hyper = pyro.sample(\"epsilon_hyper\", dist.Beta(1.0, 1 / epsilon0))\n",
    "    alpha_hyper = pyro.sample(\"alpha_hyper\", dist.Gamma(alpha0, 1.0))\n",
    "    pi_hyper = pyro.sample(\"pi_hyper\", dist.Gamma(pi0, 1.0))\n",
    "\n",
    "    with pyro.plate(\"sample\", n, dim=-1):\n",
    "        # Construct pi from PowerPert distribution\n",
    "        # TODO: Add back rho influence\n",
    "        pi_raw = pyro.sample('pi_raw', dist.Dirichlet(rho * s))\n",
    "        log_pi_raw_pow = torch.log(pi_raw) / (pi_hyper)\n",
    "        log_pi = log_pi_raw_pow - torch.logsumexp(log_pi_raw_pow, -1, keepdim=True)\n",
    "        pi = pyro.deterministic('pi', torch.exp(log_pi))\n",
    "        \n",
    "        alpha = pyro.sample(\"alpha\", dist.Gamma(alpha_hyper, 1.0)).unsqueeze(\n",
    "            -1\n",
    "        )\n",
    "        epsilon = pyro.sample(\n",
    "            \"epsilon\", dist.Beta(1.0, 1 / epsilon_hyper)\n",
    "        ).unsqueeze(-1)\n",
    "    # pi.shape == (n, s)\n",
    "    # alpha.shape == epsilon.shape == (n,)\n",
    "\n",
    "    p_noerr = pyro.deterministic(\"p_noerr\", pi @ gamma)\n",
    "    p = pyro.deterministic(\n",
    "        \"p\", (1 - epsilon / 2) * (p_noerr) + (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    # p.shape == (n, g)\n",
    "\n",
    "    y = pyro.sample(\n",
    "        \"y\",\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m,\n",
    "        ),\n",
    "        obs=y,\n",
    "    )\n",
    "    # y.shape == (n, g)\n",
    "    return y\n",
    "\n",
    "def conditioned_model(\n",
    "    model, data={}, dtype=torch.float32, device=\"cpu\", **kwargs,\n",
    "):\n",
    "    data = {\n",
    "        k: torch.tensor(v, dtype=dtype, device=device) for k, v in data.items()\n",
    "    }\n",
    "    return partial(\n",
    "        pyro.condition(model, data=data), dtype=dtype, device=device, **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def find_map(\n",
    "    model,\n",
    "    lag=10,\n",
    "    stop_at=1.0,\n",
    "    max_iter=int(1e5),\n",
    "    learning_rate=1e-0,\n",
    "    clip_norm=100.0,\n",
    "    auto_guide=pyro.infer.autoguide.AutoLaplaceApproximation,\n",
    "    num_samples=1,\n",
    "):\n",
    "    guide = auto_guide(model)\n",
    "    svi = pyro.infer.SVI(\n",
    "        model,\n",
    "        guide,\n",
    "        pyro.optim.Adamax(\n",
    "            optim_args={\"lr\": learning_rate},\n",
    "            clip_args={\"clip_norm\": clip_norm},\n",
    "        ),\n",
    "        loss=pyro.infer.JitTrace_ELBO(),\n",
    "    )\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pbar = tqdm(range(max_iter), position=0, leave=True)\n",
    "    history = []\n",
    "    try:\n",
    "        for i in pbar:\n",
    "            elbo = svi.step()\n",
    "\n",
    "            if np.isnan(elbo):\n",
    "                break\n",
    "\n",
    "            # Fit tracking\n",
    "            history.append(elbo)\n",
    "\n",
    "            # Reporting/Breaking\n",
    "            if i < 2:\n",
    "                pbar.set_postfix({\"ELBO\": history[-1]})\n",
    "            elif i < lag + 1:\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"ELBO\": history[-1],\n",
    "                        \"delta_1\": history[-2] - history[-1],\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                delta_lag = (history[-lag] - history[-1]) / lag\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"ELBO\": history[-1],\n",
    "                        \"delta_1\": history[-2] - history[-1],\n",
    "                        f\"delta_{lag}\": delta_lag,\n",
    "                    }\n",
    "                )\n",
    "                if delta_lag < stop_at:\n",
    "                    info(\"Optimization converged\")\n",
    "                    break\n",
    "    except KeyboardInterrupt:\n",
    "        info(\"Optimization interrupted\")\n",
    "    pbar.refresh()\n",
    "    assert delta_lag < stop_at, (\n",
    "        f\"Reached {args.max_iter} iterations with a per-step improvement of \"\n",
    "        f\"{args.delta_lag}. Consider setting --max-iter \"\n",
    "        f\"or --stop-at larger; increasing --learning-rate may also help, \"\n",
    "        f\"although it could also lead to numerical issues.\"\n",
    "    )\n",
    "    # Gather MAP from parameter-store\n",
    "    mapest = {\n",
    "        k: v.detach().cpu().numpy().squeeze()\n",
    "        for k, v in pyro.infer.Predictive(\n",
    "            model, guide=guide, num_samples=num_samples,\n",
    "        )().items()\n",
    "    }\n",
    "    return mapest, np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim, g_sim = 300, 200\n",
    "m_sim = 10 * np.ones((n_sim, g_sim))\n",
    "s_sim = 100\n",
    "\n",
    "model_sim = conditioned_model(\n",
    "    model,\n",
    "    data=dict(\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=1e-2,\n",
    "        rho_hyper=1e-0,\n",
    "        epsilon_hyper=0.01,\n",
    "        alpha_hyper=1000,\n",
    "    ),\n",
    "    s=s_sim,\n",
    "    m=m_sim,\n",
    ")\n",
    "\n",
    "sim = pyro.infer.Predictive(model_sim, num_samples=1)()\n",
    "sim = {k: sim[k].detach().cpu().numpy().squeeze() for k in sim}\n",
    "#sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim['pi'].max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim['rho'], sim['pi'].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(sim['pi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(sim['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = conditioned_model(\n",
    "    model,\n",
    "    data=dict(\n",
    "        gamma_hyper=0.01,\n",
    "        pi_hyper=1e-2,\n",
    "        rho_hyper=1e-0,\n",
    "        epsilon_hyper=0.01,\n",
    "        alpha_hyper=1000,\n",
    "        y=sim['y'],\n",
    "    ),\n",
    "    s=s_sim,\n",
    "    m=m_sim,\n",
    ")\n",
    "\n",
    "mapest, history = find_map(\n",
    "    model_fit, learning_rate=1e-1, lag=200,\n",
    "    auto_guide=partial(pyro.infer.autoguide.AutoLowRankMultivariateNormal, rank=10),\n",
    "    num_samples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(mapest['gamma'].mean(0), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(mapest['pi'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mapest['rho'], mapest['pi'].mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(mapest['p_noerr'] - sim['p']).sum() / (n_sim * g_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapest.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mapest['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.dirichlet.logpdf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore distributions formed by powering of dirichlet distributed random variables.\n",
    "\n",
    "def closure(x):\n",
    "    x = np.asarray(x)\n",
    "    return x / x.sum(-1)\n",
    "\n",
    "xx = np.linspace(0.0000001, 0.9999999, num=10000)\n",
    "alpha = np.array([1.01, 1, 1])\n",
    "log_prob = np.apply_along_axis(lambda x: scipy.stats.dirichlet(alpha).logpdf([x, (1 - x)/2, (1-x)/2]), 0, xx)\n",
    "plt.plot(xx, log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(x):\n",
    "    x = np.asarray(x)\n",
    "    return x / x.sum(-1, keepdims=True)\n",
    "\n",
    "def repeat(f, n=1):\n",
    "    return np.stack([f() for _ in range(n)])\n",
    "\n",
    "\n",
    "p = 6/11\n",
    "alpha = 2.0\n",
    "\n",
    "p = np.array([p, (1 - p)])\n",
    "p_raised = (p / p.min())\n",
    "\n",
    "x = closure(scipy.stats.dirichlet(p_raised).rvs(100000)**alpha)[:, 0]\n",
    "plt.hist(x, bins=100)\n",
    "print(np.geomean(x))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}