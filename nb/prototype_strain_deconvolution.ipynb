{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.util import info, idxwhere\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "import arviz as az\n",
    "from pyro.ops.contract import einsum\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rss(x, y):\n",
    "    return np.sqrt(np.sum((x - y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = 'data/core/100022/gtpro.read_r1.tsv.bz2'\n",
    "\n",
    "data = (\n",
    "    pd.read_table(\n",
    "        inpath,\n",
    "        names=[\n",
    "            \"library_id\",\n",
    "            \"species_id\",\n",
    "            \"snp_idx\",\n",
    "            \"_3\",\n",
    "            \"_4\",\n",
    "            \"_5\",\n",
    "            \"_6\",\n",
    "            \"ref\",\n",
    "            \"alt\",\n",
    "        ],\n",
    "        index_col=[\"library_id\", \"species_id\", \"snp_idx\"],\n",
    "    )[[\"ref\", \"alt\"]]\n",
    "    .rename_axis(columns=\"allele\")\n",
    "    .stack()\n",
    "    .to_xarray().fillna(0).astype(int).squeeze()\n",
    ")\n",
    "info(data.sizes)\n",
    "\n",
    "cvrg = data.sum('allele')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    s,\n",
    "    m,\n",
    "    y=None,\n",
    "    gamma_hyper=torch.tensor(0.).double(),\n",
    "    pi0=torch.tensor(1.).double(),\n",
    "    rho0=torch.tensor(1.).double(),\n",
    "    epsilon0=torch.tensor(0.01).double(),\n",
    "    alpha0=torch.tensor(1000.).double(),\n",
    "):\n",
    "    \n",
    "    n, g = m.shape\n",
    "    \n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.Beta(torch.exp(-gamma_hyper), torch.exp(-gamma_hyper))\n",
    "            )\n",
    "#    assert gamma.shape[-2:] == torch.Size([s, g])\n",
    "    \n",
    "    rho_hyper = pyro.sample('rho_hyper', dist.Gamma(rho0, 1.))\n",
    "    rho = pyro.sample('rho', dist.Dirichlet(torch.ones(s).double() * rho_hyper))\n",
    "    \n",
    "    epsilon_hyper = pyro.sample('epsilon_hyper', dist.Beta(1., 1 / epsilon0))\n",
    "    alpha_hyper = pyro.sample('alpha_hyper', dist.Gamma(alpha0, 1.))\n",
    "    \n",
    "    pi_hyper = pyro.sample('pi_hyper', dist.Gamma(pi0, 1.))\n",
    "    \n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        pi = pyro.sample('pi', dist.Dirichlet(rho * pi_hyper))\n",
    "#    assert pi.shape[-2:] == torch.Size([n, s])\n",
    "        alpha = pyro.sample('alpha', dist.Gamma(alpha_hyper, 1.)).unsqueeze(-1)\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ gamma)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "#    assert p.shape[-2:] == torch.Size([n, g])\n",
    "\n",
    "#     # Mini-batch indexing\n",
    "#     batch_p = p  # pyro.ops.indexing.Vindex(p)[..., batch_ii, :][..., batch_jj]\n",
    "#     batch_m = pyro.ops.indexing.Vindex(m)[..., batch_ii, :][..., batch_jj]\n",
    "#     if y is not None:\n",
    "#         batch_y = pyro.ops.indexing.Vindex(y)[..., batch_ii, :][..., batch_jj]\n",
    "#     else:\n",
    "#         batch_y = None\n",
    "        \n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ),\n",
    "        obs=y\n",
    "    )\n",
    "#    assert y.shape[-2:] == torch.Size([n, g])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def guide_conditioned(\n",
    "    s,\n",
    "    m,\n",
    "    y=None,\n",
    "    pi0=torch.tensor(1.),\n",
    "    epsilon0=torch.tensor(0.01),\n",
    "    alpha0=torch.tensor(100.),\n",
    "):\n",
    "    n, g = m.shape\n",
    "    \n",
    "    \n",
    "#     gamma_a = pyro.param(\n",
    "#         'gamma_a',\n",
    "#         init_tensor=torch.ones(s, g),\n",
    "#         constraint=dist.constraints.positive,\n",
    "#     )\n",
    "#     gamma_b = pyro.param(\n",
    "#         'gamma_b',\n",
    "#         init_tensor=torch.ones(s, g),\n",
    "#         constraint=dist.constraints.positive,\n",
    "#     )\n",
    "#     pyro.sample('gamma', dist.Beta(gamma_a, gamma_b))\n",
    "    gamma_loc = pyro.param(\n",
    "        'gamma_loc',\n",
    "        init_tensor=torch.ones(s, g) * 0.5,\n",
    "        constraint=dist.constraints.interval(1e-5, 1 - 1e-5),\n",
    "    )\n",
    "    pyro.sample('gamma', dist.Delta(gamma_loc))\n",
    "\n",
    "        \n",
    "    alpha_log = pyro.param(\n",
    "        'alpha_log',\n",
    "        init_tensor=torch.ones(n) * torch.log(alpha0),\n",
    "    )\n",
    "    pyro.sample('alpha', dist.Delta(torch.exp(alpha_log)))\n",
    "    \n",
    "    epsilon_interval = pyro.param(\n",
    "        'epsilon_interval',\n",
    "        init_tensor=torch.ones(n) * torch.logit(epsilon0 * 2)\n",
    "    )\n",
    "    pyro.sample('epsilon', dist.Delta(torch.sigmoid(epsilon_interval) / 2))\n",
    "    \n",
    "    pi_simplex = pyro.param(\n",
    "        'pi_simplex',\n",
    "        init_tensor=torch.zeros(n, s - 1),\n",
    "        constraint=dist.constraints.interval(-35, 35),\n",
    "    )\n",
    "    pyro.sample(\n",
    "        'pi',\n",
    "        dist.Delta(\n",
    "            torch.softmax(\n",
    "                torch.cat([torch.zeros(n, 1), pi_simplex], dim=-1),\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples with >25% of positions covered\n",
    "high_cvrg_samples = (data.sum('allele') > 0).mean('snp_idx') > 0.25\n",
    "print(high_cvrg_samples.sum().values)\n",
    "\n",
    "position_ss = np.random.randint(data.shape[1], size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = data[high_cvrg_samples, position_ss]\n",
    "s = 400\n",
    "m = torch.tensor(_data.sum('allele').values).double()\n",
    "n, g = m.shape\n",
    "y_obs = torch.tensor(_data.sel(allele='alt').values).double()\n",
    "\n",
    "model_fit = partial(\n",
    "    pyro.condition(\n",
    "        model,\n",
    "        data={\n",
    "          'alpha_hyper': torch.tensor(100.).double(),\n",
    "          'epsilon_hyper': torch.tensor(0.01).double(),\n",
    "          'pi_hyper': torch.tensor(1e-5).double(),\n",
    "          'rho_hyper': torch.tensor(1.0).double(),\n",
    "#           'epsilon': torch.ones(n) * 0.001,\n",
    "#           'rho': torch.ones(s).double() / s,\n",
    "        }\n",
    "    ),\n",
    "    s=s,\n",
    "    m=m,\n",
    "    gamma_hyper=torch.tensor(20.).double(),\n",
    "#     pi0=torch.tensor(1e-1).double(),\n",
    "#    rho0=torch.tensor(1.),\n",
    "#    alpha0=torch.tensor(100.),  # These two params have no effect IF we condition\n",
    "#    epsilon0=torch.tensor(0.01),  #  on epsilon_hyper and alpha_hyper\n",
    ")\n",
    "\n",
    "trace = pyro.poutine.trace(model_fit).get_trace()\n",
    "trace.compute_log_prob()\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_guide = partial(guide_conditioned, s=s, m=m)\n",
    "#_guide = pyro.infer.autoguide.AutoDiagonalNormal(model_fit, )\n",
    "#_guide = pyro.infer.autoguide.AutoNormal(model_fit, )\n",
    "#_guide = pyro.infer.autoguide.AutoLowRankMultivariateNormal(model_fit, rank=100)\n",
    "_guide = pyro.infer.autoguide.AutoLaplaceApproximation(model_fit)\n",
    "#_guide = pyro.infer.autoguide.AutoIAFNormal(model_fit, hidden_dim=[500], num_transforms=3)\n",
    "#_guide = pyro.infer.autoguide.AutoDelta(model_fit)\n",
    "\n",
    "opt = pyro.optim.Adamax({\"lr\": 1e-1}, {\"clip_norm\": 100.})\n",
    "#opt = pyro.optim.RMSprop({\"lr\": 0.001})\n",
    "\n",
    "svi = pyro.infer.SVI(\n",
    "    model_fit,\n",
    "    _guide,\n",
    "    opt,\n",
    "    loss=pyro.infer.JitTrace_ELBO()\n",
    ")\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "pbar = tqdm(range(10000))\n",
    "history = []\n",
    "delta_history = []\n",
    "# trace_epsilon_interval = []\n",
    "# trace_gamma_a = []\n",
    "# trace_gamma_b = []\n",
    "# trace_gamma_loc = []\n",
    "# trace_alpha_log = []\n",
    "# trace_pi_simplex = []\n",
    "for i in pbar:\n",
    "    elbo = svi.step(\n",
    "        y=y_obs,\n",
    "    )\n",
    "    \n",
    "    if np.isnan(elbo):\n",
    "        break\n",
    "\n",
    "    # Fit tracking\n",
    "    history.append(elbo)\n",
    "    \n",
    "    # Reporting/Breaking\n",
    "    if (i % 1 == 0):\n",
    "        if i > 1:\n",
    "            pbar.set_postfix({'ELBO': history[-1], 'delta': history[-2] - history[-1]})\n",
    "#         trace_epsilon_interval.append(pyro.get_param_store()['epsilon_interval'].detach().numpy().copy())\n",
    "#         trace_gamma_a.append(pyro.get_param_store()['gamma_a'].detach().numpy().copy())\n",
    "#         trace_gamma_b.append(pyro.get_param_store()['gamma_b'].detach().numpy().copy())\n",
    "# #         trace_gamma_loc.append(pyro.get_param_store()['gamma_loc'].detach().numpy().copy())\n",
    "#         trace_alpha_log.append(pyro.get_param_store()['alpha_log'].detach().numpy().copy())\n",
    "#         trace_pi_simplex.append(pyro.get_param_store()['pi_simplex'].detach().numpy().copy())\n",
    "#     if np.mean(delta_history[-1000:]) < 0.0001:\n",
    "#         break\n",
    "\n",
    "        \n",
    "pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_predictive = pyro.infer.Predictive(model_fit, guide=partial(_guide, s=s, m=m), num_samples=1)\n",
    "svi_posterior = {k: v.detach().numpy()\n",
    "                 for k, v\n",
    "                 in svi_predictive(y=y_obs).items()}\n",
    "#posterior_predictive = svi_predictive()['y']\n",
    "\n",
    "#fit_pi = fit_pi.rename(columns=lambda i: f\"fit_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_fit = pd.DataFrame(svi_posterior['pi'].mean(0).mean(0))\n",
    "sns.clustermap(pi_fit)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.quantile(trace_pi_simplex[-1], [0, 0.5, 0.75, 0.95, 0.99, 1.], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(sp.special.softmax(trace_pi_simplex[100], axis=-1).max(1), bins=np.linspace(0., 1,))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([trace_epsilon_interval[i].mean() for i in range(len(trace_epsilon_interval))])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([trace_alpha_log[i].mean() for i in range(len(trace_alpha_log))])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = -1\n",
    "\n",
    "gamma_fit = trace_gamma_a[-1] / (trace_gamma_a[-1] + trace_gamma_b[-1])\n",
    "\n",
    "sns.heatmap(gamma_fit.T)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(pd.DataFrame(sp.special.softmax(trace_pi_simplex[-1], axis=1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([trace_pi_simplex[i].max() for i in range(len(trace_pi_simplex))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pi_fit.max(1).sort_values(ascending=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pi_fit.max(0).sort_values(ascending=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit = pd.DataFrame(svi_posterior['gamma'].squeeze())\n",
    "\n",
    "sns.clustermap(gamma_fit.T)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(y_obs, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_obs = y_obs.numpy() / m.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(frac_obs[:,:], cmap='coolwarm', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_expect = (pi_fit @ gamma_fit) #* m.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(frac_expect, cmap='coolwarm', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(frac_obs - frac_expect, cmap='coolwarm')\n",
    "\n",
    "np.abs(((frac_obs - frac_expect) * m.numpy())).sum().sum() / m.numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(svi_posterior['alpha'].squeeze(), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(svi_posterior['epsilon'].squeeze(), bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_fit_drop = pi_fit.loc[:, (pi_fit.max(0) > 0.01)]\n",
    "gamma_fit_drop = gamma_fit.loc[(pi_fit.max(0) > 0.01), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data2 = data[:, position_ss]\n",
    "s2 = pi_fit_drop.shape[1]\n",
    "m2 = torch.tensor(_data2.sum('allele').values).double()\n",
    "n2, g2 = m2.shape\n",
    "y_obs2 = torch.tensor(_data2.sel(allele='alt').values).double()\n",
    "\n",
    "model_fit2 = partial(\n",
    "    pyro.condition(\n",
    "        model,\n",
    "        data={\n",
    "          'alpha_hyper': torch.tensor(100.).double(),\n",
    "          'epsilon_hyper': torch.tensor(0.01).double(),\n",
    "          'pi_hyper': torch.tensor(1e-5).double(),\n",
    "          'rho_hyper': torch.tensor(1.0).double(),\n",
    "          'gamma': torch.tensor(gamma_fit_drop.values).double(),\n",
    "#           'epsilon': torch.ones(n) * 0.001,\n",
    "#           'rho': torch.ones(s).double() / s,\n",
    "        }\n",
    "    ),\n",
    "    s=s2,\n",
    "    m=m2,\n",
    "    gamma_hyper=torch.tensor(20.).double(),\n",
    "#     pi0=torch.tensor(1e-1).double(),\n",
    "#    rho0=torch.tensor(1.),\n",
    "#    alpha0=torch.tensor(100.),  # These two params have no effect IF we condition\n",
    "#    epsilon0=torch.tensor(0.01),  #  on epsilon_hyper and alpha_hyper\n",
    ")\n",
    "\n",
    "trace2 = pyro.poutine.trace(model_fit2).get_trace()\n",
    "trace2.compute_log_prob()\n",
    "print(trace2.format_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_guide2 = partial(guide_conditioned, s=s2, m=m2)\n",
    "#_guide2 = pyro.infer.autoguide.AutoDiagonalNormal(model_fit2, )\n",
    "#_guide2 = pyro.infer.autoguide.AutoNormal(model_fit2, )\n",
    "#_guide2 = pyro.infer.autoguide.AutoLowRankMultivariateNormal(model_fit2, rank=100)\n",
    "_guide2 = pyro.infer.autoguide.AutoLaplaceApproximation(model_fit2)\n",
    "#_guide2 = pyro.infer.autoguide.AutoIAFNormal(model_fit2, hidden_dim=[500], num_transforms=3)\n",
    "#_guide2 = pyro.infer.autoguide.AutoDelta(model_fit2)\n",
    "\n",
    "opt = pyro.optim.Adamax({\"lr\": 1e-1}, {\"clip_norm\": 100.})\n",
    "#opt = pyro.optim.RMSprop({\"lr\": 0.001})\n",
    "\n",
    "svi2 = pyro.infer.SVI(\n",
    "    model_fit2,\n",
    "    _guide2,\n",
    "    opt,\n",
    "    loss=pyro.infer.JitTrace_ELBO()\n",
    ")\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "pbar = tqdm(range(10000))\n",
    "history2 = []\n",
    "for i in pbar:\n",
    "    elbo = svi2.step(\n",
    "        y=y_obs2,\n",
    "    )\n",
    "    \n",
    "    if np.isnan(elbo):\n",
    "        break\n",
    "\n",
    "    # Fit tracking\n",
    "    history2.append(elbo)\n",
    "    \n",
    "    # Reporting/Breaking\n",
    "    if (i % 1 == 0):\n",
    "        if i > 1:\n",
    "            pbar.set_postfix({'ELBO': history2[-1], 'delta': history2[-2] - history2[-1]})\n",
    "#         trace_epsilon_interval.append(pyro.get_param_store()['epsilon_interval'].detach().numpy().copy())\n",
    "#         trace_gamma_a.append(pyro.get_param_store()['gamma_a'].detach().numpy().copy())\n",
    "#         trace_gamma_b.append(pyro.get_param_store()['gamma_b'].detach().numpy().copy())\n",
    "# #         trace_gamma_loc.append(pyro.get_param_store()['gamma_loc'].detach().numpy().copy())\n",
    "#         trace_alpha_log.append(pyro.get_param_store()['alpha_log'].detach().numpy().copy())\n",
    "#         trace_pi_simplex.append(pyro.get_param_store()['pi_simplex'].detach().numpy().copy())\n",
    "#     if np.mean(delta_history[-1000:]) < 0.0001:\n",
    "#         break\n",
    "\n",
    "        \n",
    "pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_predictive2 = pyro.infer.Predictive(model_fit2, guide=partial(_guide2, s=s2, m=m2), num_samples=1)\n",
    "svi_posterior2 = {k: v.detach().numpy()\n",
    "                 for k, v\n",
    "                 in svi_predictive2(y=y_obs2).items()}\n",
    "#posterior_predictive = svi_predictive()['y']\n",
    "\n",
    "#fit_pi = fit_pi.rename(columns=lambda i: f\"fit_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(svi_posterior2['pi'].squeeze().max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(gamma_fit_drop.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_fit = pd.DataFrame(svi_posterior['pi'].mean(0).mean(0))\n",
    "sns.clustermap(pi_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_fit2 = pd.DataFrame(svi_posterior2['pi'].mean(0).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    pi_fit.max(1).values,\n",
    "    pi_fit2.max(1)[high_cvrg_samples].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatcmap(pi_fit.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pi_fit2.loc[list(high_cvrg_samples)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pi_fit2.max(1).sort_values(ascending=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pi_fit2.max(0).sort_values(ascending=False).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cvrg.mean('snp_idx'), pi_fit2.max(1), s=2)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}