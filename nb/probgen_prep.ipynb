{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "theoretical-happiness",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.util.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.py\n",
    "\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "def info(*msg):\n",
    "    now = datetime.now()\n",
    "    print(f'[{now}]', *msg, file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.py\n",
    "\n",
    "def as_torch(x, dtype=None, device=None):\n",
    "    # Cast inputs and set device\n",
    "    return torch.tensor(x, dtype=dtype, device=device)\n",
    "\n",
    "def all_torch(dtype=None, device=None, **kwargs):\n",
    "    # Cast inputs and set device\n",
    "    return {k: as_torch(kwargs[k], dtype=dtype, device=device) for k in kwargs}\n",
    "\n",
    "# pyro.py\n",
    "\n",
    "def shape_info(model, *args, **kwargs):\n",
    "    _trace = pyro.poutine.trace(model).get_trace(*args, **kwargs)\n",
    "    _trace.compute_log_prob()\n",
    "    info(_trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-empire",
   "metadata": {},
   "source": [
    "## Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "\n",
    "def NegativeBinomialReparam(mu, r, eps=1e-5):\n",
    "    p = torch.clamp(1. / ((r / mu) + 1.), min=eps, max=1. - eps)\n",
    "    return dist.NegativeBinomial(\n",
    "        total_count=r,\n",
    "        probs=p\n",
    "    )\n",
    "\n",
    "\n",
    "def model_binomial(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=1.,\n",
    "    rho_hyper=1.,\n",
    "    pi_hyper=1.,\n",
    "    epsilon_hyper_hyper=0.01,\n",
    "    mu_hyper_mean=1.,\n",
    "    mu_hyper_scale=1.,\n",
    "    m_hyper_r=1.,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "):\n",
    "    \n",
    "    gamma_hyper, rho_hyper, pi_hyper, epsilon_hyper_hyper, mu_hyper_mean, mu_hyper_scale, m_hyper_r = (\n",
    "        as_torch(x, dtype=dtype, device=device)\n",
    "        for x in [gamma_hyper, rho_hyper, pi_hyper, epsilon_hyper_hyper, mu_hyper_mean, mu_hyper_scale, m_hyper_r]\n",
    "    )\n",
    "\n",
    "    # Genotypes\n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, logits=torch.tensor(0, dtype=dtype, device=device))\n",
    "            )\n",
    "    \n",
    "    # Meta-community composition\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s, dtype=dtype, device=device)))\n",
    "\n",
    "    epsilon_hyper = pyro.sample('epsilon_hyper', dist.Beta(1., 1 / epsilon_hyper_hyper))\n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        # Community composition\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        # Sample coverage\n",
    "        mu = pyro.sample('mu', dist.LogNormal(loc=torch.log(mu_hyper_mean), scale=mu_hyper_scale))\n",
    "        # Sequencing error\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        \n",
    "    # Sample/position coverage\n",
    "    m = pyro.sample('m', NegativeBinomialReparam(mu.reshape((-1, 1)), m_hyper_r).expand([n, g]).to_event())\n",
    "    \n",
    "    # Error model\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ gamma)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    \n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.Binomial(\n",
    "            probs=p,\n",
    "            total_count=m\n",
    "        ).to_event(),\n",
    "    )\n",
    "    \n",
    "def model_betabinomial(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=1.,\n",
    "    rho_hyper=1.,\n",
    "    pi_hyper=1.,\n",
    "    alpha_hyper_hyper_mean=100.,\n",
    "    alpha_hyper_hyper_scale=10.,\n",
    "    alpha_hyper_scale=0.5,\n",
    "    epsilon_hyper_hyper=0.01,\n",
    "    mu_hyper_mean=1.,\n",
    "    mu_hyper_scale=1.,\n",
    "    m_hyper_r=1.,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "):\n",
    "    \n",
    "    gamma_hyper, rho_hyper, pi_hyper, alpha_hyper_hyper_mean, alpha_hyper_hyper_scale, alpha_hyper_scale, epsilon_hyper_hyper, mu_hyper_mean, mu_hyper_scale, m_hyper_r = (\n",
    "        as_torch(x, dtype=dtype, device=device)\n",
    "        for x in [\n",
    "            gamma_hyper,\n",
    "            rho_hyper,\n",
    "            pi_hyper,\n",
    "            alpha_hyper_hyper_mean,\n",
    "            alpha_hyper_hyper_scale,\n",
    "            alpha_hyper_scale,\n",
    "            epsilon_hyper_hyper,\n",
    "            mu_hyper_mean,\n",
    "            mu_hyper_scale,\n",
    "            m_hyper_r,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Genotypes\n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, logits=torch.tensor(0, dtype=dtype, device=device))\n",
    "            )\n",
    "    \n",
    "    # Meta-community composition\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s, dtype=dtype, device=device)))\n",
    "\n",
    "    alpha_hyper_mean = pyro.sample('alpha_hyper_mean', dist.LogNormal(loc=torch.log(alpha_hyper_hyper_mean), scale=alpha_hyper_hyper_scale))\n",
    "    epsilon_hyper = pyro.sample('epsilon_hyper', dist.Beta(1., 1 / epsilon_hyper_hyper))\n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        # Community composition\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        # Sample coverage\n",
    "        mu = pyro.sample('mu', dist.LogNormal(loc=torch.log(mu_hyper_mean), scale=mu_hyper_scale))\n",
    "        # Sequencing error\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        alpha = pyro.sample('alpha', dist.LogNormal(loc=torch.log(alpha_hyper_mean), scale=alpha_hyper_scale)).unsqueeze(-1)\n",
    "        \n",
    "    # Sample/position coverage\n",
    "    m = pyro.sample('m', NegativeBinomialReparam(mu.reshape((-1, 1)), m_hyper_r).expand([n, g]).to_event())\n",
    "    \n",
    "    # Error model\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ gamma)\n",
    "    p = pyro.deterministic(\n",
    "        'p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    \n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ).to_event(),\n",
    "    )\n",
    "    \n",
    "    \n",
    "def model_binomial_missing(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=1.,\n",
    "    delta_hyper_temp=0.1,\n",
    "    delta_hyper_p=0.9,\n",
    "    rho_hyper=1.,\n",
    "    pi_hyper=1.,\n",
    "    epsilon_hyper_hyper=0.01,\n",
    "    mu_hyper_mean=1.,\n",
    "    mu_hyper_scale=1.,\n",
    "    m_hyper_r=1.,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "):\n",
    "    \n",
    "    (\n",
    "        gamma_hyper,\n",
    "        delta_hyper_temp,\n",
    "        delta_hyper_p,\n",
    "        rho_hyper,\n",
    "        pi_hyper,\n",
    "        epsilon_hyper_hyper,\n",
    "        mu_hyper_mean,\n",
    "        mu_hyper_scale,\n",
    "        m_hyper_r,\n",
    "    ) = (\n",
    "        as_torch(x, dtype=dtype, device=device)\n",
    "        for x in [\n",
    "            gamma_hyper,\n",
    "            delta_hyper_temp,\n",
    "            delta_hyper_p,\n",
    "            rho_hyper,\n",
    "            pi_hyper,\n",
    "            epsilon_hyper_hyper,\n",
    "            mu_hyper_mean,\n",
    "            mu_hyper_scale,\n",
    "            m_hyper_r,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Genotypes\n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, logits=torch.tensor(0, dtype=dtype, device=device))\n",
    "            )\n",
    "            # Position presence/absence\n",
    "            delta = pyro.sample(\n",
    "                'delta', dist.RelaxedBernoulli(temperature=delta_hyper_temp, probs=delta_hyper_p)\n",
    "            )\n",
    "    \n",
    "    # Meta-community composition\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s, dtype=dtype, device=device)))\n",
    "\n",
    "    epsilon_hyper = pyro.sample('epsilon_hyper', dist.Beta(1., 1 / epsilon_hyper_hyper))\n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        # Community composition\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        # Sample coverage\n",
    "        mu = pyro.sample('mu', dist.LogNormal(loc=torch.log(mu_hyper_mean), scale=mu_hyper_scale))\n",
    "        # Sequencing error\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        \n",
    "    # Depth at each position\n",
    "    nu = pyro.deterministic(\"nu\", pi @ delta)\n",
    "    m = pyro.sample('m', NegativeBinomialReparam(nu * mu.reshape((-1,1)), m_hyper_r).to_event())\n",
    "  \n",
    "    # Expected fractions of each allele at each position\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ (gamma * delta) / nu)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.Binomial(\n",
    "            probs=p,\n",
    "            total_count=m\n",
    "        ).to_event(),\n",
    "    )\n",
    "    \n",
    "def model_betabinomial_missing(\n",
    "    n,\n",
    "    g,\n",
    "    s,\n",
    "    gamma_hyper=1.,\n",
    "    delta_hyper_temp=0.1,\n",
    "    delta_hyper_p=0.9,\n",
    "    rho_hyper=1.,\n",
    "    pi_hyper=1.,\n",
    "    alpha_hyper_hyper_mean=100.,\n",
    "    alpha_hyper_hyper_scale=10.,\n",
    "    alpha_hyper_scale=0.5,\n",
    "    epsilon_hyper_hyper=0.01,\n",
    "    mu_hyper_mean=1.,\n",
    "    mu_hyper_scale=1.,\n",
    "    m_hyper_r=1.,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "):\n",
    "    \n",
    "    (\n",
    "        gamma_hyper,\n",
    "        delta_hyper_temp,\n",
    "        delta_hyper_p,\n",
    "        rho_hyper,\n",
    "        pi_hyper,\n",
    "        alpha_hyper_hyper_mean,\n",
    "        alpha_hyper_hyper_scale,\n",
    "        alpha_hyper_scale,\n",
    "        epsilon_hyper_hyper,\n",
    "        mu_hyper_mean,\n",
    "        mu_hyper_scale,\n",
    "        m_hyper_r\n",
    "    ) = (\n",
    "        as_torch(x, dtype=dtype, device=device)\n",
    "        for x in [\n",
    "            gamma_hyper,\n",
    "            delta_hyper_temp,\n",
    "            delta_hyper_p,\n",
    "            rho_hyper,\n",
    "            pi_hyper,\n",
    "            alpha_hyper_hyper_mean,\n",
    "            alpha_hyper_hyper_scale,\n",
    "            alpha_hyper_scale,\n",
    "            epsilon_hyper_hyper,\n",
    "            mu_hyper_mean,\n",
    "            mu_hyper_scale,\n",
    "            m_hyper_r,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Genotypes\n",
    "    with pyro.plate('position', g, dim=-1):\n",
    "        with pyro.plate('strain', s, dim=-2):\n",
    "            gamma = pyro.sample(\n",
    "                'gamma', dist.RelaxedBernoulli(temperature=gamma_hyper, logits=torch.tensor(0, dtype=dtype, device=device))\n",
    "            )\n",
    "            # Position presence/absence\n",
    "            delta = pyro.sample(\n",
    "                'delta', dist.RelaxedBernoulli(temperature=delta_hyper_temp, probs=delta_hyper_p)\n",
    "            )\n",
    "    \n",
    "    # Meta-community composition\n",
    "    rho = pyro.sample('rho', dist.RelaxedOneHotCategorical(temperature=rho_hyper, logits=torch.zeros(s, dtype=dtype, device=device)))\n",
    "\n",
    "    alpha_hyper_mean = pyro.sample('alpha_hyper_mean', dist.LogNormal(loc=torch.log(alpha_hyper_hyper_mean), scale=alpha_hyper_hyper_scale))\n",
    "    epsilon_hyper = pyro.sample('epsilon_hyper', dist.Beta(1., 1 / epsilon_hyper_hyper))\n",
    "    with pyro.plate('sample', n, dim=-1):\n",
    "        # Community composition\n",
    "        pi = pyro.sample('pi', dist.RelaxedOneHotCategorical(temperature=pi_hyper, probs=rho))\n",
    "        # Sample coverage\n",
    "        mu = pyro.sample('mu', dist.LogNormal(loc=torch.log(mu_hyper_mean), scale=mu_hyper_scale))\n",
    "        # Sequencing error\n",
    "        epsilon = pyro.sample('epsilon', dist.Beta(1., 1 / epsilon_hyper)).unsqueeze(-1)\n",
    "        alpha = pyro.sample('alpha', dist.LogNormal(loc=torch.log(alpha_hyper_mean), scale=alpha_hyper_scale)).unsqueeze(-1)\n",
    "        \n",
    "    # Depth at each position\n",
    "    nu = pyro.deterministic(\"nu\", pi @ delta)\n",
    "    m = pyro.sample('m', NegativeBinomialReparam(nu * mu.reshape((-1,1)), m_hyper_r).to_event())\n",
    "\n",
    "    # Expected fractions of each allele at each position\n",
    "    p_noerr = pyro.deterministic('p_noerr', pi @ (gamma * delta) / nu)\n",
    "    p = pyro.deterministic('p',\n",
    "        (1 - epsilon / 2) * (p_noerr) +\n",
    "        (epsilon / 2) * (1 - p_noerr)\n",
    "    )\n",
    "    \n",
    "    # Observation\n",
    "    y = pyro.sample(\n",
    "        'y',\n",
    "        dist.BetaBinomial(\n",
    "            concentration1=alpha * p,\n",
    "            concentration0=alpha * (1 - p),\n",
    "            total_count=m\n",
    "        ).to_event(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_info(model_binomial_missing, n=100, g=200, s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-studio",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-directory",
   "metadata": {},
   "source": [
    "### SimShape-1: Small study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate.py\n",
    "\n",
    "def condition_model(model, data=None, device='cpu', dtype=torch.float32, **model_kwargs):\n",
    "    if data is None:\n",
    "        data = {}\n",
    "        \n",
    "    conditioned_model = partial(\n",
    "        pyro.condition(\n",
    "            model,\n",
    "            data=all_torch(**data, dtype=dtype, device=device),\n",
    "        ),\n",
    "        **model_kwargs,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "    return conditioned_model\n",
    "    \n",
    "def simulate(model):\n",
    "    obs = pyro.infer.Predictive(model, num_samples=1)()\n",
    "    obs = {\n",
    "        k: obs[k].detach().cpu().numpy().squeeze()\n",
    "        for k in obs.keys()\n",
    "    }\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 2000\n",
    "g_sim = 1000\n",
    "s_sim = 50\n",
    "\n",
    "sim1 = simulate(\n",
    "    condition_model(\n",
    "        model_betabinomial_missing,\n",
    "        data=dict(alpha_hyper_mean=100.),\n",
    "        n=n_sim,\n",
    "        g=g_sim,\n",
    "        s=s_sim,\n",
    "        gamma_hyper=0.01,\n",
    "        delta_hyper_temp=0.01,\n",
    "        delta_hyper_p=0.7,\n",
    "        pi_hyper=0.5,\n",
    "        rho_hyper=2.,\n",
    "        mu_hyper_mean=2.,\n",
    "        mu_hyper_scale=0.5,\n",
    "        m_hyper_r=10.,\n",
    "        alpha_hyper_scale=0.5,\n",
    "        epsilon_hyper_hyper=0.01,\n",
    "        device='cuda'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-transmission",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genotype.py\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy as sp\n",
    "\n",
    "def prob_to_sign(gamma):\n",
    "    return gamma * 2 - 1\n",
    "\n",
    "# TODO: Demonstrate that the \"genotype_distance\" defined above, degrades well under decreasing coverage and increasing missingness.\n",
    "def genotype_distance(x, y):\n",
    "    x = prob_to_sign(x)\n",
    "    y = prob_to_sign(y)\n",
    "    dist = ((x - y) / 2) ** 2\n",
    "    weight = (x * y) ** 2\n",
    "    wmean_dist = ((weight * dist).mean()) / ((weight.mean()))\n",
    "    return wmean_dist\n",
    "\n",
    "# TODO: Demonstrate that the \"genotype_distance\" defined above, degrades well under decreasing coverage and increasing missingness.\n",
    "def sign_genotype_distance(x, y):\n",
    "    dist = ((x - y) / 2) ** 2\n",
    "    weight = (x * y) ** 2\n",
    "    wmean_dist = ((weight * dist).mean()) / ((weight.mean()))\n",
    "    return wmean_dist\n",
    "\n",
    "def genotype_pdist(gamma):\n",
    "    return pdist(gamma, metric=genotype_distance)\n",
    "\n",
    "def genotype_pdist2(gamma, progress=False):\n",
    "    metric = sign_genotype_distance\n",
    "    X = np.asarray(gamma * 2 - 1)\n",
    "    m = X.shape[0]\n",
    "    dm = np.empty((m * (m - 1)) // 2)\n",
    "    k = 0\n",
    "    with tqdm(total=len(dm), disable=(not progress)) as pbar:\n",
    "        for i in range(0, m - 1):\n",
    "            for j in range(i + 1, m):\n",
    "                dm[k] = metric(X[i], X[j])\n",
    "                k = k + 1\n",
    "                pbar.update()\n",
    "    return dm\n",
    "    \n",
    "\n",
    "# TODO: Try out cosine instead of 'genotype_distance'\n",
    "# def genotype_pdist(gamma):\n",
    "#     return pdist(gamma * 2 - 1, metric='cosine')\n",
    "\n",
    "def counts_to_p_estimate(y, m, pseudo=1):\n",
    "    return (y + pseudo) / (m + pseudo * 2)\n",
    "\n",
    "def genotype_linkage(gamma, progress=False, **kwargs):\n",
    "    dmat = genotype_pdist2(gamma, progress=progress)\n",
    "    kw = dict(method='complete')\n",
    "    kw.update(kwargs)\n",
    "    return sp.cluster.hierarchy.linkage(dmat, **kw), dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot.py\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_genotype(gamma, linkage_kw=None, **kwargs):\n",
    "    if linkage_kw is None:\n",
    "        linkage_kw = {}\n",
    "    linkage, _ = genotype_linkage(gamma, **linkage_kw)\n",
    "    \n",
    "    gamma_t = gamma.T\n",
    "    ny, nx = gamma_t.shape\n",
    "    \n",
    "    mwidth = nx * 0.15\n",
    "    mheight = ny * 0.02\n",
    "    dwidth = 0.2\n",
    "    dheight = 1.0\n",
    "    fwidth = mwidth + dwidth\n",
    "    fheight = mheight + dheight\n",
    "    dendrogram_ratio = (dwidth / fwidth, dheight / fheight)\n",
    "    \n",
    "    kw = dict(\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        cmap='coolwarm',\n",
    "        dendrogram_ratio=dendrogram_ratio,\n",
    "        col_linkage=linkage,\n",
    "        figsize=(fwidth, fheight),\n",
    "        xticklabels=1,\n",
    "        yticklabels=0,\n",
    "    )\n",
    "    kw.update(kwargs)\n",
    "    sns.clustermap(prob_to_sign(gamma_t), **kw)\n",
    "    \n",
    "def plot_missing(delta, **kwargs):\n",
    "    delta_t = delta.T\n",
    "    ny, nx = delta_t.shape\n",
    "    \n",
    "    mwidth = nx * 0.15\n",
    "    mheight = ny * 0.02\n",
    "    dwidth = 0.2\n",
    "    dheight = 1.0\n",
    "    fwidth = mwidth + dwidth\n",
    "    fheight = mheight + dheight\n",
    "    dendrogram_ratio = (dwidth / fwidth, dheight / fheight)\n",
    "    \n",
    "    kw = dict(\n",
    "        vmin=0, vmax=1, dendrogram_ratio=dendrogram_ratio, figsize=(fwidth, fheight), xticklabels=1, yticklabels=0,\n",
    "    )\n",
    "    kw.update(kwargs)\n",
    "    sns.clustermap(delta_t, **kw)\n",
    "    \n",
    "def plot_community(pi, **kwargs):\n",
    "    ny, nx = pi.shape\n",
    "    \n",
    "    mwidth = nx * 0.2\n",
    "    mheight = ny * 0.1\n",
    "    dwidth = 0.2\n",
    "    dheight = 1.0\n",
    "    fwidth = mwidth + dwidth\n",
    "    fheight = mheight + dheight\n",
    "    dendrogram_ratio = (dwidth / fwidth, dheight / fheight)\n",
    "    \n",
    "    kw = dict(\n",
    "        metric='cosine', vmin=0, vmax=1, dendrogram_ratio=dendrogram_ratio, figsize=(fwidth, fheight), xticklabels=1,\n",
    "    )\n",
    "    kw.update(kwargs)\n",
    "    sns.clustermap(pi, **kw)\n",
    "    \n",
    "def plot_genotype_similarity(gamma, linkage_kw=None, **kwargs):\n",
    "    if linkage_kw is None:\n",
    "        linkage_kw = {}\n",
    "    linkage, dmat = genotype_linkage(gamma, **linkage_kw)\n",
    "    dmat = squareform(dmat)\n",
    "    \n",
    "    nx = ny = gamma.shape[0]\n",
    "    \n",
    "    mwidth = nx * 0.15\n",
    "    mheight = ny * 0.15\n",
    "    dwidth = 0.5\n",
    "    dheight = 0.5\n",
    "    fwidth = mwidth + dwidth\n",
    "    fheight = mheight + dheight\n",
    "    dendrogram_ratio = (dwidth / fwidth, dheight / fheight)\n",
    "    \n",
    "    kw = dict(\n",
    "        vmin=0, vmax=1, dendrogram_ratio=dendrogram_ratio, row_linkage=linkage, col_linkage=linkage, figsize=(fwidth, fheight), xticklabels=1, yticklabels=1,\n",
    "    )\n",
    "    kw.update(kwargs)\n",
    "    sns.clustermap(1 - dmat, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plt = 100\n",
    "g_plt = 200\n",
    "s_plt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype(counts_to_p_estimate(sim1['y'][:n_plt, :g_plt], sim1['m'][:n_plt, :g_plt]), linkage_kw=dict(progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype_similarity(counts_to_p_estimate(sim1['y'][:n_plt, :g_plt], sim1['m'][:n_plt, :g_plt]), linkage_kw=dict(progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_community(sim1['pi'][:s_plt, :n_plt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype(sim1['gamma'][:s_plt, :g_plt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing(sim1['delta'][:s_plt, :g_plt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing(sim1['nu'][:n_plt, :g_plt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(sim1['m'][:n_plt, :g_plt], norm=mpl.colors.SymLogNorm(linthresh=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype_similarity(sim1['gamma'][:s_plt, :g_plt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-cooling",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-arthur",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def cluster_genotypes(\n",
    "    gamma, thresh, progress=False\n",
    "):\n",
    "    \n",
    "\n",
    "    clust = pd.Series(\n",
    "        AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            affinity=\"precomputed\",\n",
    "            linkage=\"complete\",\n",
    "            distance_threshold=thresh,\n",
    "        )\n",
    "        .fit(squareform(genotype_pdist2(gamma, progress=progress)))\n",
    "        .labels_\n",
    "    )\n",
    "\n",
    "    return clust\n",
    "\n",
    "def initialize_parameters_by_clustering_samples(\n",
    "    y, m, thresh, additional_strains_factor=0.5, progress=False,\n",
    "):\n",
    "    n, g = y.shape\n",
    "\n",
    "    sample_genotype = (y + 1) / (m + 2)\n",
    "    clust = cluster_genotypes(sample_genotype, thresh=thresh, progress=progress)\n",
    "\n",
    "    y_total = (\n",
    "        pd.DataFrame(pd.DataFrame(y))\n",
    "        .groupby(clust)\n",
    "        .sum()\n",
    "        .values\n",
    "    )\n",
    "    m_total = (\n",
    "        pd.DataFrame(pd.DataFrame(m))\n",
    "        .groupby(clust)\n",
    "        .sum()\n",
    "        .values\n",
    "    )\n",
    "    clust_genotype = (y_total + 1) / (m_total + 2)\n",
    "    additional_haplotypes = int(\n",
    "        additional_strains_factor * clust_genotype.shape[0]\n",
    "    )\n",
    "\n",
    "\n",
    "    gamma_init = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(clust_genotype),\n",
    "            pd.DataFrame(np.ones((additional_haplotypes, g)) * 0.5),\n",
    "        ]\n",
    "    ).values\n",
    "\n",
    "    s_init = gamma_init.shape[0]\n",
    "    pi_init = np.ones((n, s_init))\n",
    "    for i in range(n):\n",
    "        pi_init[i, clust[i]] = s_init - 1\n",
    "    pi_init /= pi_init.sum(1, keepdims=True)\n",
    "\n",
    "    assert (~np.isnan(gamma_init)).all()\n",
    "\n",
    "    return gamma_init, pi_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fit = 200  # sim1['y'].shape[1]\n",
    "n_fit = sim1['y'].shape[0]\n",
    "\n",
    "sim1_gamma_init, sim1_pi_init = initialize_parameters_by_clustering_samples(\n",
    "    sim1['y'][:n_fit, :g_fit],\n",
    "    sim1['m'][:n_fit, :g_fit],\n",
    "    thresh=0.1,\n",
    "    additional_strains_factor=0.0,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "print(sim1_pi_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype(sim1_gamma_init[:s_plt, :g_plt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype_similarity(sim1_gamma_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_community(sim1_pi_init[:n_plt, :s_plt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-limitation",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation.py\n",
    "\n",
    "def estimate_parameters(\n",
    "    model,\n",
    "    data,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    "    initialize_params=None,\n",
    "    maxiter=10000,\n",
    "    lag=100,\n",
    "    lr=1e-0,\n",
    "    clip_norm=100,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    conditioned_model = condition_model(\n",
    "        model,\n",
    "        data=data,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "    if initialize_params is None:\n",
    "        initialize_params = {}\n",
    "\n",
    "    _guide = pyro.infer.autoguide.AutoLaplaceApproximation(\n",
    "        conditioned_model,\n",
    "        init_loc_fn=pyro.infer.autoguide.initialization.init_to_value(\n",
    "            values=all_torch(**initialize_params, dtype=dtype, device=device)\n",
    "        ),\n",
    "    )\n",
    "    opt = pyro.optim.Adamax({\"lr\": lr}, {\"clip_norm\": clip_norm})\n",
    "    svi = pyro.infer.SVI(\n",
    "        conditioned_model,\n",
    "        _guide,\n",
    "        opt,\n",
    "        loss=pyro.infer.JitTrace_ELBO()\n",
    "    )\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    history = []\n",
    "    pbar = tqdm(range(maxiter))\n",
    "    try:\n",
    "        for i in pbar:\n",
    "            elbo = svi.step()\n",
    "\n",
    "            if np.isnan(elbo):\n",
    "                raise RuntimeError(\"ELBO NaN?\")\n",
    "\n",
    "            # Fit tracking\n",
    "            history.append(elbo)\n",
    "\n",
    "            # Reporting/Breaking\n",
    "            if (i % 10 == 0):\n",
    "                if i > lag:\n",
    "                    delta = history[-2] - history[-1]\n",
    "                    delta_lag = (history[-lag] - history[-1]) / lag\n",
    "                    if delta_lag <= 0:\n",
    "                        info(\"Converged\")\n",
    "                        break\n",
    "                    pbar.set_postfix({\n",
    "                        'ELBO': history[-1],\n",
    "                        'delta': delta,\n",
    "                        f'lag{lag}': delta_lag,\n",
    "                    })\n",
    "    except KeyboardInterrupt:\n",
    "        info(\"Interrupted\")\n",
    "        pass\n",
    "    finally:         \n",
    "        est = pyro.infer.Predictive(conditioned_model, guide=_guide, num_samples=1)()\n",
    "        est = {\n",
    "            k: est[k].detach().cpu().numpy().mean(0).squeeze()\n",
    "            for k in est.keys()\n",
    "        }\n",
    "    return est, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fit = sim1_gamma_init.shape[0]\n",
    "initialize_params = dict(gamma=sim1_gamma_init, pi=sim1_pi_init)\n",
    "\n",
    "sim1_fit1, history = estimate_parameters(\n",
    "    model_betabinomial_missing,\n",
    "    data=dict(y=sim1['y'][:, :g_fit], m=sim1['m'][:, :g_fit]),\n",
    "    n=n_fit,\n",
    "    g=g_fit,\n",
    "    s=s_fit,\n",
    "    gamma_hyper=0.1,\n",
    "    pi_hyper=1.0,\n",
    "    rho_hyper=0.5,\n",
    "    mu_hyper_mean=5,\n",
    "    mu_hyper_scale=5.,\n",
    "    m_hyper_r=10.,\n",
    "    delta_hyper_temp=0.01,\n",
    "    delta_hyper_p=0.9,\n",
    "    alpha_hyper_hyper_mean=100.,\n",
    "    alpha_hyper_hyper_scale=10.,\n",
    "    alpha_hyper_scale=0.5,\n",
    "    initialize_params=initialize_params,\n",
    "    device='cuda',\n",
    "    lag=1000,\n",
    "    lr=1e-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(trace):\n",
    "    trace = np.array(trace)\n",
    "    plt.plot((trace - trace.min()))\n",
    "    plt.yscale('log')\n",
    "    \n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-commissioner",
   "metadata": {},
   "source": [
    "### Merging Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_similar_genotypes(\n",
    "    gamma, pi, thresh, delta=None,\n",
    "):\n",
    "    if delta is None:\n",
    "        delta = np.ones_like(gamma)\n",
    "\n",
    "    clust = cluster_genotypes(gamma * delta, thresh=thresh)\n",
    "    gamma_mean = (\n",
    "        pd.DataFrame(pd.DataFrame(gamma))\n",
    "        .groupby(clust)\n",
    "        .apply(lambda x: sp.special.expit(sp.special.logit(x)).mean(0))\n",
    "        .values\n",
    "    )\n",
    "    pi_sum = (\n",
    "        pd.DataFrame(pd.DataFrame(pi))\n",
    "        .groupby(clust, axis='columns')\n",
    "        .sum()\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    return gamma_mean, pi_sum\n",
    "\n",
    "sim1_fit1_gamma_merge, sim1_fit1_pi_merge = merge_similar_genotypes(\n",
    "    sim1_fit1['gamma'],\n",
    "    sim1_fit1['pi'],\n",
    "    thresh=0.1,\n",
    ")\n",
    "\n",
    "# print(sim1_gamma_init.shape[0], sim1_fit1['gamma'].shape[0], sim1_fit1_gamma_merge.shape[0])\n",
    "print(sim1_fit1['gamma'].shape[0], sim1_fit1_gamma_merge.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-letter",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_missing_genotype(gamma, delta):\n",
    "    return sp.special.expit(sp.special.logit(gamma) * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_gamma_adjusted = mask_missing_genotype(sim1['gamma'][:, :g_fit], sim1['delta'][:, :g_fit])\n",
    "sim1_fit1_gamma_adjusted = mask_missing_genotype(sim1_fit1['gamma'], sim1_fit1['delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-croatia",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-surprise",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genotype_comparison(data=None, **kwargs):\n",
    "    stacked = pd.concat([\n",
    "        pd.DataFrame(data[k], index=[f'{k}_{i}' for i in range(data[k].shape[0])])\n",
    "        for k in data\n",
    "    ])\n",
    "    kw = dict(xticklabels=1)\n",
    "    kw.update(kwargs)\n",
    "    plot_genotype(stacked, **kw)\n",
    "\n",
    "def plot_community_comparison(data=None, **kwargs):\n",
    "    stacked = pd.concat([\n",
    "        pd.DataFrame(data[k], columns=[f'{k}_{i}' for i in range(data[k].shape[1])])\n",
    "        for k in data\n",
    "    ], axis=1)\n",
    "    kw = dict(xticklabels=1)\n",
    "    kw.update(kwargs)\n",
    "    plot_community(stacked, **kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype_comparison(\n",
    "    data=dict(\n",
    "        true=sim1_gamma_adjusted[:, :g_plt],\n",
    "#         fit=sim1_fit1['gamma'][:, :g_plt],\n",
    "        adj=sim1_fit1_gamma_adjusted[:, :g_plt],\n",
    "#         init=sim1_gamma_init,\n",
    "#         merg=sim1_fit1_gamma_merge,\n",
    "    ),\n",
    "    linkage_kw=dict(progress=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_community_comparison(\n",
    "    data=dict(\n",
    "        true=sim1['pi'],\n",
    "        fit=sim1_fit1['pi'],\n",
    "#         init=sim1_pi_init,\n",
    "#         merg=sim1_fit1_pi_merge,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim1['epsilon'], sim1_fit1['epsilon'])\n",
    "plt.plot([0, 0.04], [0, 0.04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim1['alpha'], sim1_fit1['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sim1_fit1['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sim1['mu'], sim1_fit1['mu'])\n",
    "plt.plot([0, 40], [0, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot comparing genotype accuracy to true strain abundance\n",
    "# colored by mean entropy of the estimated genotype masked by delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-charlotte",
   "metadata": {},
   "source": [
    "#### Fit scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_entropy(p):\n",
    "    q = 1 - p\n",
    "    ent = -(p * np.log2(p) + q * np.log2(q))\n",
    "    return ent\n",
    "\n",
    "def sum_binary_entropy(p, normalize=False, axis=None):\n",
    "    q = 1 - p\n",
    "    ent = np.sum(-(p * np.log2(p) + q * np.log2(q)), axis=axis)\n",
    "    if normalize:\n",
    "        ent = ent / p.shape[axis]\n",
    "    return ent\n",
    "\n",
    "def mean_masked_genotype_entropy(gamma, delta):\n",
    "    return (binary_entropy(gamma) * delta).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality of genotypes.\n",
    "# For each true genotype, compare its genotype to the\n",
    "# best inferred genotype.\n",
    "# This is our score for the quality of the genotype inferences.\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "\n",
    "def best_genotype_hits(gammaA, gammaB):\n",
    "    dist = pd.DataFrame(cdist(gammaA, gammaB, metric='cityblock'))\n",
    "    return dist.idxmin(axis=1), dist.min(axis=1)\n",
    "\n",
    "best_hit, best_dist = best_genotype_hits(sim1_gamma_adjusted[:, :g_fit], sim1_fit1_gamma_adjusted[:, :g_fit])\n",
    "\n",
    "print('weighted_mean_distance:', (best_dist * sim1['pi'].mean(0)).sum())\n",
    "plt.scatter(sim1['pi'].sum(0), best_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality of abundance estimates\n",
    "# Compare BC distance matrices for inferences to the true distance matrix\n",
    "\n",
    "bc_sim = 1 - pdist(sim1['pi'], metric='braycurtis')\n",
    "bc_fit = 1 - pdist(sim1_fit1['pi'], metric='braycurtis')\n",
    "\n",
    "plt.scatter(\n",
    "    bc_sim,\n",
    "    bc_fit,\n",
    "    marker='.',\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "print(np.abs(bc_sim - bc_fit).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-sheffield",
   "metadata": {},
   "source": [
    "### No Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-november",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype(sim1_fit1_gamma_adjusted[:, :g_plt], linkage_kw=dict(progress=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_community(sim1_fit1['pi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strains that are not representative of true haplotypes\n",
    "# are high entropy (even after masking with delta)\n",
    "# and have low estimated total coverage.\n",
    "\n",
    "best_true_strain, best_true_strain_dist = best_genotype_hits(sim1_fit1_gamma_adjusted[:, :g_fit], sim1_gamma_adjusted[:, :g_fit])\n",
    "best_true_strain_dist\n",
    "\n",
    "plt.scatter((sim1_fit1['pi'] * sim1_fit1['mu'].reshape((-1, 1))).sum(0), best_true_strain_dist, c=mean_masked_genotype_entropy(sim1_fit1['gamma'], sim1_fit1['delta']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-birth",
   "metadata": {},
   "source": [
    "#### Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_masked_genotype_entropy(sim1_fit1['gamma'][:, :g_plt], sim1_fit1['delta'][:, :g_plt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genotype(sim1_fit1['gamma'][mean_masked_genotype_entropy(sim1_fit1['gamma'], sim1_fit1['delta']) < 0.1, :g_fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-burton",
   "metadata": {},
   "source": [
    "## Estimation on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-bangladesh",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}